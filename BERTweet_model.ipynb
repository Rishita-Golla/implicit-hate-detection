{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERTweet_model.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"f036be50dbc84bee87f60cc316970196":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_72b953de0e3447d4af24a16dfa80d590","IPY_MODEL_884a29f537f540a0b1aa889052245483"],"layout":"IPY_MODEL_fd20b8f28a324bc8b6173f6be4d75d53"}},"72b953de0e3447d4af24a16dfa80d590":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_80338170689543cd83198514589069a9","placeholder":"​","style":"IPY_MODEL_af6d3cca37e14ad9a8b07ae897533d14","value":"0.739 MB of 0.739 MB uploaded (0.000 MB deduped)\r"}},"884a29f537f540a0b1aa889052245483":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ed4bfff8e66467982b24346c5ed4384","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_89aac94f0e7240fe9b05339a8ac29e5b","value":1}},"fd20b8f28a324bc8b6173f6be4d75d53":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80338170689543cd83198514589069a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af6d3cca37e14ad9a8b07ae897533d14":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5ed4bfff8e66467982b24346c5ed4384":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89aac94f0e7240fe9b05339a8ac29e5b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"kvf7fqACrBnE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652312525169,"user_tz":240,"elapsed":3058,"user":{"displayName":"Pragya Sarda","userId":"11319887257693684769"}},"outputId":"dd6d8a77-8063-4638-f9e5-a223d795cc06"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.6.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.53)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","source":["!pip install emoji"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zdaxheRj14VZ","executionInfo":{"status":"ok","timestamp":1652312529703,"user_tz":240,"elapsed":4537,"user":{"displayName":"Pragya Sarda","userId":"11319887257693684769"}},"outputId":"83bb0fbd-e076-4e8d-abe6-a640817cb2e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (1.7.0)\n"]}]},{"cell_type":"code","source":["!pip install wandb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_A3-Z7b918yE","executionInfo":{"status":"ok","timestamp":1652312534685,"user_tz":240,"elapsed":4999,"user":{"displayName":"Pragya Sarda","userId":"11319887257693684769"}},"outputId":"1268a995-6497-4572-c506-d0d77fa9eb1b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.12.16)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.27)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.5.12)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (from wandb) (1.2.3)\n","Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.9)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.2.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n"]}]},{"cell_type":"code","source":["#!wget -c https://repo.continuum.io/archive/Anaconda3-5.1.0-Linux-x86_64.sh"],"metadata":{"id":"H0sArSAlzrpu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#!chmod +x Anaconda3-5.1.0-Linux-x86_64.sh\n","#!bash ./Anaconda3-5.1.0-Linux-x86_64.sh -b -f -p /usr/local"],"metadata":{"id":"7biOLZaGzuVy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !python --version"],"metadata":{"id":"Ia-yEejw2UA_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !which python # should return /usr/local/bin/python\n","# !python --version\n","# !echo $PYTHONPATH\n","# %env PYTHONPATH="],"metadata":{"id":"qeHyoUaU2VYh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#%%bash\n","#MINICONDA_INSTALLER_SCRIPT=Miniconda3-4.5.4-Linux-x86_64.sh\n","#MINICONDA_PREFIX=/usr/local\n","#wget https://repo.continuum.io/miniconda/$MINICONDA_INSTALLER_SCRIPT\n","#chmod +x $MINICONDA_INSTALLER_SCRIPT\n","#./$MINICONDA_INSTALLER_SCRIPT -b -f -p $MINICONDA_PREFIX"],"metadata":{"id":"Ub-BvNKa46WL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#!which conda\n","#!conda --version"],"metadata":{"id":"tAset4b05LJY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#!which python"],"metadata":{"id":"RYRgWtho5fuT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#!python --version"],"metadata":{"id":"D_rM0jNR5gQW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#%%bash\n","#conda install --channel defaults conda python=3.6 --yes\n","#conda update --channel defaults --all --yes"],"metadata":{"id":"ROPhn65K5iiT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import sys\n","# sys.path"],"metadata":{"id":"zkq9JhAL86dT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !ls /usr/local/lib/python3.6/dist-packages"],"metadata":{"id":"NU_tv8x0ap4k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import sys\n","# _ = (sys.path\n","#         .append(\"/usr/local/lib/python3.6/site-packages\"))"],"metadata":{"id":"X1MgjXoWaqgS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#!conda install --channel conda-forge featuretools --yes"],"metadata":{"id":"2syr4jH1avBt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#!conda create -n cs685"],"metadata":{"id":"6xvs5MpIaveC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#!conda update -n base -c defaults conda"],"metadata":{"id":"BeV7QGbssdmP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#!activate cs685"],"metadata":{"id":"UuMO8OO4bPiU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"LT-_TvDtcwlQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652312535767,"user_tz":240,"elapsed":793,"user":{"displayName":"Pragya Sarda","userId":"11319887257693684769"}},"outputId":"3847dae0-a3a9-40b0-96a0-584acac3fa02"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/685-NLP-Project/implicit-hate-detection"],"metadata":{"id":"Q6ApBsYyuqjK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652312535768,"user_tz":240,"elapsed":21,"user":{"displayName":"Pragya Sarda","userId":"11319887257693684769"}},"outputId":"33ef803f-9def-44cc-bd60-e7856dc400c7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/685-NLP-Project/implicit-hate-detection\n"]}]},{"cell_type":"code","source":["#!git clone https://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@github.com/kimberley-faria/implicit-hate-detection"],"metadata":{"id":"iCthwVEzvZBW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# %cd /content/drive/MyDrive/Github/685/implicit-hate-detection"],"metadata":{"id":"ue1u7KDAwxLJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#!git clone https://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@github.com/kimberley-faria/implicit-hate-detection"],"metadata":{"id":"HJWhRP0vw0VF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pwd"],"metadata":{"id":"lCrHMiPUsddU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652312536276,"user_tz":240,"elapsed":515,"user":{"displayName":"Pragya Sarda","userId":"11319887257693684769"}},"outputId":"fa0ac6fe-9fc7-4ca6-a55c-613d82bc213b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/685-NLP-Project/implicit-hate-detection\n"]}]},{"cell_type":"code","source":["%ls -a"],"metadata":{"id":"eXGF0IvQxjic","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652312536276,"user_tz":240,"elapsed":6,"user":{"displayName":"Pragya Sarda","userId":"11319887257693684769"}},"outputId":"5a15222e-536d-4eea-8e2a-d436f4d4726f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" Anaconda3-5.1.0-Linux-x86_64.sh\n","'BERTweet_model-hate vs nonhate.ipynb'\n"," BERTweet_model.ipynb\n"," config.json\n","'Copy of BERTweet_model.ipynb'\n","'Copy of implicit_hate_detection_multi_class.ipynb'\n"," \u001b[0m\u001b[01;34m.git\u001b[0m/\n"," .gitignore\n"," hsol_final_model.bin\n","'HSOL implicit_hate_detection_multi_class.ipynb'\n"," \u001b[01;34mimplicit_hate_dataloader\u001b[0m/\n"," implicit_hate_detection_hate_vs_non_hate_bertweet.ipynb\n"," implicit_hate_detection_hate_vs_non_hate.ipynb\n"," implicit_hate_detection_implicit_hate_vs_non_hate.ipynb\n"," implicit_hate_detection.ipynb\n"," implicit_hate_detection_multi_class.ipynb\n"," implicit_hate_detection_multi.ipynb\n"," model.h5\n"," README.md\n"," req_instructions.md\n"," requirements.txt\n"," \u001b[01;34mwandb\u001b[0m/\n"]}]},{"cell_type":"code","source":["#!git add ."],"metadata":{"id":"NsmNO4aRxpbU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#!git commit -m \"check\""],"metadata":{"id":"mscWo5mxxyob"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import sys\n","\n","if 'google.colab' in sys.modules:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    base_path = '/content/drive/MyDrive/685-NLP-Project/implicit-hate-detection'"],"metadata":{"id":"JgH7ziijyX9G","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652312537372,"user_tz":240,"elapsed":1098,"user":{"displayName":"Pragya Sarda","userId":"11319887257693684769"}},"outputId":"b858abec-198d-4177-c3de-5834e7a590bb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# %cd $base_path\n","# !git checkout 5-bert-baselines-bin-classification-hate-non-hate"],"metadata":{"id":"wzMyLk8kykf7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%load implicit_hate_dataloader/dataloader.py    \n","%load implicit_hate_dataloader/helpers.py"],"metadata":{"id":"lfWIyO6dyqKv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","data_path = '/content/drive/MyDrive/685-NLP-Project/implicit-hate-corpus'\n","dataset_filename = {\n","    # post (str)\n","    # class (str): high-level label in {`explicit_hate`,`implicit_hate`,`not_hate`}\n","    \"stage-1\": os.path.join(data_path, \"implicit_hate_v1_stg1_posts.tsv\"),\n","\n","    # post (str)\n","    # class (str): fine-grained implicit hate label in\n","    # {`white_grievance`, `incitement`, `inferiority`, `irony`, `stereotypical`, `threatening`, `other`}\n","    # extra_implicit_class: (str) A secondary fine-grained implicit hate label in\n","    # {`white_grievance`, `incitement`, `inferiority`, `irony`, `stereotypical`, `threatening`, `other`, **None**}\n","    \"stage-2\": os.path.join(data_path, \"implicit_hate_v1_stg2_posts.tsv\"),\n","\n","    # post (str)\n","    # target: (str) Free-text annotation for the group being targeted (e.g. `Black people`, `Immigrants`, etc.)\n","    # implied_statement: (str) Free-text annotation for the implicit or hidden underlying meaning of the post made\n","    # explicit (e.g. `people in minority groups are all in gangs`)\n","    \"stage-3\": os.path.join(data_path, \"implicit_hate_v1_stg3_posts.tsv\")\n","}"],"metadata":{"id":"0utlzpjF2sVM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from implicit_hate_dataloader.dataloader import Stage1Dataset, Stage2Dataset\n","from torch.utils.data import DataLoader"],"metadata":{"id":"2gkkA-Z-3GGL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Stage 1 Annotations: see config.py for dataset spec\n","import torch\n","\n","implicit_hate_dataset = Stage1Dataset(dataset_filename[\"stage-1\"], merge_hate_labels =True)\n","#print(type(implicit_hate_dataset))\n","\n","# implicit_hate_dataset = torch.topk(implicit_hate_dataset, 20)\n","\n","dataset_size = len(implicit_hate_dataset)\n","#dataset_splits = [int(0.006*dataset_size), int(0.002*dataset_size), int(0.002*dataset_size)]\n","dataset_splits = [int(0.6*dataset_size), int(0.2*dataset_size), dataset_size - int(0.6*dataset_size) - int(0.2*dataset_size)]\n","\n","# # Smaller dataset for testing model\n","# dataset_splits = [int(0.006*dataset_size), int(0.002*dataset_size), int(0.002*dataset_size)]\n","print(\"Dataset size\", dataset_size)\n","print(\"Dataset splits\", dataset_splits)\n","\n","train_set, val_set, test_set = torch.utils.data.random_split(implicit_hate_dataset, dataset_splits)\n","# print(train_set.shape, type(train_set))\n","\n","train_dataloader =  DataLoader(train_set, batch_size=4, shuffle=True)\n","validation_dataloader = DataLoader(val_set, batch_size=4, shuffle=True)"],"metadata":{"id":"gSoV4CGOB8yu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652312556905,"user_tz":240,"elapsed":19263,"user":{"displayName":"Pragya Sarda","userId":"11319887257693684769"}},"outputId":"24dc35bc-1e8d-41d3-e413-e4ed2a0278c0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset size 21480\n","Dataset splits [12888, 4296, 4296]\n"]}]},{"cell_type":"code","source":["text, label, input_ids, attention_masks, labels = next(iter(train_dataloader))\n","print(text, type(label), type(input_ids), type(attention_masks), type(labels))"],"metadata":{"id":"6-WhzqO3B0yi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652312556905,"user_tz":240,"elapsed":16,"user":{"displayName":"Pragya Sarda","userId":"11319887257693684769"}},"outputId":"c784c110-297a-4bf3-df12-7f0965555f4b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["('this is inciting hatred and violence against so please act strongly on this racist propaganda !', \"we'll see you ... in september ! #vvs16\", \"i'd like to hear more from #joshduggar and the family research council about the sanctity of marriage . #bwahaha !\", \"none ! semites aren't white .\") <class 'tuple'> <class 'torch.Tensor'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score\n","\n","def calculate_scores(preds, labels):\n","    pred_flat = np.argmax(np.concatenate(preds), axis=1).flatten()\n","    results = dict()\n","    results['precision_score'] = precision_score(labels, pred_flat, average='binary')\n","    results['recall_score'] = recall_score(labels, pred_flat, average='binary')\n","    results['f1_score'] = f1_score(labels, pred_flat, average='binary')\n","    return results\n"],"metadata":{"id":"iKaw3AigcUFH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from transformers import AutoModel, AutoTokenizer \n","\n","# tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\" )\n","\n","# new_train_set = \n","\n","# for i in range(0,len(train_set)):\n","#   text = train_set[i][0]\n","#   inputs_list = list(tokenizer(text, return_tensors = \"pt\"))\n","#   train_set[i][2] = tuple(train_set[i][2])\n","\n","# for i in range(0,len(val_set)):\n","#   text = val_set[i][0]\n","#   inputs = list(tokenizer(text, return_tensors = \"pt\"))\n","#   val_set[i][2] = tuple(inputs)\n","\n","# for i in range(0,len(test_set)):\n","#   text = test_set[i][0]\n","#   inputs = list(tokenizer(text, return_tensors = \"pt\"))\n","#   test_set[i][2] = tuple(inputs)\n"],"metadata":{"id":"EAVT3_urQuKL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","assert torch.cuda.is_available()\n","\n","# Get the GPU device name.\n","device_name = torch.cuda.get_device_name()\n","n_gpu = torch.cuda.device_count()\n","print(f\"Found device: {device_name}, n_gpu: {n_gpu}\")\n","device = torch.device(\"cuda\")"],"metadata":{"id":"LKVo0dAYF4fc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652312556906,"user_tz":240,"elapsed":11,"user":{"displayName":"Pragya Sarda","userId":"11319887257693684769"}},"outputId":"e72f7ab3-577a-4145-b6bc-bda086d5466f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found device: Tesla P100-PCIE-16GB, n_gpu: 1\n"]}]},{"cell_type":"code","source":["from torch import nn\n","\n","loss_fn = nn.CrossEntropyLoss().to(device)\n","# loss_fn = nn.CrossEntropyLoss()"],"metadata":{"id":"vzrny80iPOYV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"metadata":{"id":"y7VrxEKqUn19"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import precision_recall_fscore_support\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","import numpy as np\n","\n","# function to get validation accuracy\n","def get_validation_performance(model, val_set, config, epoch, dataset):\n","    # Put the model in evaluation mode\n","    model.eval()\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","\n","    validation_dataloader = DataLoader(val_set, batch_size=config[\"batch_size\"], shuffle=True)\n","\n","    total_correct = 0\n","\n","    predicted = []\n","    labels = []\n","\n","    for batch in validation_dataloader:\n","      # Move tensors to the GPU\n","      b_input_ids = batch[2].to(device)\n","      b_input_mask = batch[3].to(device)\n","      b_labels = batch[4].to(device)\n","        \n","      # Tell pytorch not to bother with constructing the compute graph during\n","      # the forward pass, since this is only needed for backprop (training).\n","      with torch.no_grad():        \n","\n","        # Forward pass, calculate logit predictions.\n","        #outputs = model(input_ids = b_input_ids, attention_mask=b_input_mask)\n","        outputs = model(b_input_ids,token_type_ids=None, \n","                                   attention_mask=b_input_mask,\n","                                   labels=b_labels)\n","        loss = outputs.loss\n","        logits = outputs.logits\n","        #print(\"output\",type(outputs), outputs)\n","\n","      logits = logits.detach().cpu().numpy()\n","      label_ids = b_labels.to('cpu').numpy()\n","        # loss = loss_fn(outputs, b_labels)\n","        # preds = np.argmax(outputs.detach().cpu().numpy(), axis=1)\n","        #print(\"preds\", preds.shape, type(preds), preds)\n","            \n","        # Accumulate the validation loss.\n","      total_eval_loss += loss.item()\n","      labels_flat = b_labels.to('cpu').numpy().flatten()\n","      labels.append(labels_flat)\n","      predicted.append(logits)\n","      total_eval_accuracy += flat_accuracy(logits, label_ids)\n","    \n","    predicted = np.concatenate(predicted)\n","    labels = np.concatenate(labels)\n","\n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_correct / len(val_set)\n","    #final_score = precision_recall_fscore_support(predicted, labels)\n","    class_names=['not_hate', 'hate']\n","    wandb.log({f\"conf_mat_{dataset}_{epoch}\" : wandb.plot.confusion_matrix(probs=None,\n","                        y_true=labels, preds=predicted,\n","                        class_names=class_names)})\n","    cm = confusion_matrix(labels, predicted, labels=[0, 1])\n","    disp = ConfusionMatrixDisplay(confusion_matrix=cm, \n","                                  display_labels=class_names)\n","    disp.plot()\n","\n","    wandb.log({f\"conf_mat_matplotlib_{dataset}_{epoch}\": plt})\n","    plt.show()\n","\n","    return avg_val_accuracy, final_score\n","\n","    #return avg_val_accuracy, final_score"],"metadata":{"id":"3CVpMJWX3QPS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !wandb login\n","!wandb login --relogin"],"metadata":{"id":"rd5Ps1XM3XWm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652312713719,"user_tz":240,"elapsed":156820,"user":{"displayName":"Pragya Sarda","userId":"11319887257693684769"}},"outputId":"00fca066-ec70-4673-bfac-2fa9327b8d35"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}]},{"cell_type":"code","source":["import wandb\n","\n","sweep_config = {\n","    \"method\" : \"grid\",\n","    \"parameters\" : {\n","        \"batch_size\": {\n","            \"values\" : [8]\n","        },\n","        \"learning_rate\" : {\n","            \"values\": [2e-5, 3e-5, 5e-5]\n","        },\n","        \"epochs\" : {\n","            \"values\" : [1, 2, 3, 4]\n","        },\n","        \"epsilon\": {\n","            \"values\" : [1e-8]\n","        },\n","    }\n","}\n","\n","# hyperparameters used in original paper\n","sweep_config = {\n","    \"name\": \"original-ppr-hparams-sweep\",\n","    \"method\" : \"grid\",\n","    \"parameters\" : {\n","        \"batch_size\": {\n","            \"values\" : [8, 16, 32]\n","        },\n","        \"learning_rate\" : {\n","            \"values\": [2e-4, 3e-4, 4e-4, 2e-5]\n","        },\n","        \"epochs\" : {\n","            \"values\" : [2, 3, 4]\n","        },\n","        \"epsilon\": {\n","            \"values\" : [1e-8]\n","        },\n","    }\n","}\n","\n","sweep_id = wandb.sweep(sweep_config, entity=\"umass-iesl-is\", project=\"cs685-project\")"],"metadata":{"id":"3Zn8vWnY3Y86","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652312713864,"user_tz":240,"elapsed":151,"user":{"displayName":"Pragya Sarda","userId":"11319887257693684769"}},"outputId":"84d23911-a995-4963-b0f8-988534cb6d14"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Create sweep with ID: vq1tboqw\n","Sweep URL: https://wandb.ai/umass-iesl-is/cs685-project/sweeps/vq1tboqw\n"]}]},{"cell_type":"code","source":["PRE_TRAINED_MODEL_NAME = \"vinai/bertweet-base\""],"metadata":{"id":"TSPjep-5MWvR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from transformers import AutoModel, AutoTokenizer\n","\n","# class SentimentClassifier(nn.Module):\n","\n","#   def __init__(self, n_classes):\n","#     super(SentimentClassifier, self).__init__()\n","#     bertweet = AutoModel.from_pretrained(\"vinai/bertweet-base\")\n","#     self.bert = bertweet.from_pretrained(PRE_TRAINED_MODEL_NAME)\n","#     self.out = nn.Linear(self.bert.config.hidden_size, 2) #768\n","  \n","#   def forward(self, input_ids, attention_mask):\n","#     _, pooled_output = self.bert(\n","#       input_ids=input_ids,\n","#       attention_mask=attention_mask,\n","#       return_dict=False\n","#     )\n","#     output = pooled_output\n","#     return self.out(output)"],"metadata":{"id":"FWlbYcMxKWvk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model = SentimentClassifier(2)\n","# model = model.to(device)"],"metadata":{"id":"dHpFIpO4WdFs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import BertForSequenceClassification, AdamW, BertConfig\n","from transformers import AutoModel, AutoTokenizer\n","from transformers import get_linear_schedule_with_warmup,AdamW,AutoModel, AutoTokenizer, AutoModelForSequenceClassification\n","from torch import nn, optim\n","\n","def train():\n","    with wandb.init() as run:\n","        config = wandb.config\n","\n","        model = AutoModelForSequenceClassification.from_pretrained(\n","        \"vinai/bertweet-base\",\n","        num_labels = 2,  \n","        output_attentions = False, \n","        output_hidden_states = False,\n","        )\n","\n","        # Tell pytorch to run this model on the GPU.\n","        model.cuda()\n","        optimizer = AdamW(model.parameters(),\n","                        lr = config[\"learning_rate\"], # args.learning_rate - default is 5e-5\n","                        eps = config[\"epsilon\"] # args.adam_epsilon  - default is 1e-8\n","                        )\n","        wandb.watch(model, log=\"all\")\n","\n","        for epoch_i in range(0, config[\"epochs\"]):\n","            # Perform one full pass over the training set.\n","\n","            print(\"\")\n","            print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, config[\"epochs\"]))\n","            print('Training...')\n","\n","            # Reset the total loss for this epoch.\n","            total_train_loss = 0\n","\n","            # Put the model into training mode.\n","            model.train()\n","\n","            # For each batch of training data...\n","            train_dataloader = DataLoader(train_set, batch_size=config[\"batch_size\"], shuffle=True)\n","\n","            for batch_idx, batch in enumerate(train_dataloader):\n","\n","                # Move tensors to the GPU\n","                b_input_ids = batch[2].to(device)\n","                b_input_mask = batch[3].to(device)\n","                b_labels = batch[4].to(device)\n","\n","                # Clear the previously calculated gradient\n","                model.zero_grad()        \n","\n","                # Perform a forward pass (evaluate the model on this training batch).\n","                outputs = model(input_ids = b_input_ids, attention_mask = b_input_mask, labels = b_labels)\n","\n","                #_, preds = torch.max(outputs, dim=1)\n","                #loss = loss_fn(outputs, b_labels)\n","\n","                loss = outputs.loss\n","                logits = outputs.logits\n","                total_train_loss += loss.item()\n","\n","                # Perform a backward pass to calculate the gradients.\n","                loss.backward()\n","\n","                # Update parameters and take a step using the computed gradient.\n","                optimizer.step()\n","                wandb.log({\n","                    \"batch_loss\": loss.item(),\n","                    \"batch\": batch_idx\n","                })\n","                \n","            # ========================================\n","            #               Validation\n","            # ========================================\n","            # After the completion of each training epoch, measure our performance on\n","            # our validation set. Implement this function in the cell above.\n","            print(f\"Total loss: {total_train_loss}\")\n","            val_acc = get_validation_performance(model, val_set, config, epoch_i, \"val\")\n","            # val_acc, (val_precision, val_recall, val_f1, val_hash) = get_validation_performance(model, val_set, config, epoch_i, \"val\")\n","            # print(val_precision, val_recall, val_f1)\n","            # print(f\"Validation accuracy: {val_acc}\")\n","\n","            # wandb.log({\n","            #     \"loss\": total_train_loss, \n","            #     \"epoch\": config[\"epochs\"], \n","            #     \"val_acc\": val_acc,\n","            #     \"val_precision\": val_precision,\n","            #     \"val_recall\": val_recall,\n","            #     \"val_f1\": val_f1\n","            #     })\n","            \n","        print(\"\")\n","        print(\"Training complete!\")\n","\n","        test_acc = get_validation_performance(model, test_set, config, 0, \"test\")\n","        print(\"val_acc\", val_acc)\n","        print(\"test_acc\", test_acc)\n","        \n","        # test_acc, (test_precision, test_recall, test_f1, test_hash) = get_validation_performance(model, test_set, config, 0, \"test\")\n","        # print(test_precision, test_recall, test_f1)\n","        # print(f\"Test accuracy: {test_acc}\")\n","        # wandb.log({\n","        #     \"test_acc\": test_acc,\n","        #     \"test_precision\": test_precision,\n","        #     \"test_recall\": test_recall,\n","        #     \"test_f1\": test_f1\n","        #     })"],"metadata":{"id":"cjHJaW_J3etV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["count = 1 # number of runs to execute\n","wandb.agent(sweep_id, function=train, count=count, entity=\"umass-iesl-is\", project=\"cs685-project\")"],"metadata":{"id":"VzVgUrjCI6vp","colab":{"base_uri":"https://localhost:8080/","height":640,"referenced_widgets":["f036be50dbc84bee87f60cc316970196","72b953de0e3447d4af24a16dfa80d590","884a29f537f540a0b1aa889052245483","fd20b8f28a324bc8b6173f6be4d75d53","80338170689543cd83198514589069a9","af6d3cca37e14ad9a8b07ae897533d14","5ed4bfff8e66467982b24346c5ed4384","89aac94f0e7240fe9b05339a8ac29e5b"]},"executionInfo":{"status":"ok","timestamp":1652312877913,"user_tz":240,"elapsed":163943,"user":{"displayName":"Pragya Sarda","userId":"11319887257693684769"}},"outputId":"10ac0961-2813-4fea-8768-a82832cf17ab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7gq9wv1o with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepsilon: 1e-08\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2e-05\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.12.16"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/drive/MyDrive/685-NLP-Project/implicit-hate-detection/wandb/run-20220511_234515-7gq9wv1o</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/umass-iesl-is/cs685-project/runs/7gq9wv1o\" target=\"_blank\">volcanic-sweep-1</a></strong> to <a href=\"https://wandb.ai/umass-iesl-is/cs685-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/umass-iesl-is/cs685-project/sweeps/vq1tboqw\" target=\"_blank\">https://wandb.ai/umass-iesl-is/cs685-project/sweeps/vq1tboqw</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["\n","======== Epoch 1 / 1 ========\n","Training...\n","Total loss: 1006.7793816030025\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f036be50dbc84bee87f60cc316970196"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch_loss</td><td>▃▅▆▆▄▆▄▅▆▆█▅▄▅▅▄▄▆▄▃▄▇▄▆▃▄▆▃▄▃▁▅▄▅▅▇▅▅▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>1610</td></tr><tr><td>batch_loss</td><td>0.53533</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Synced <strong style=\"color:#cdcd00\">volcanic-sweep-1</strong>: <a href=\"https://wandb.ai/umass-iesl-is/cs685-project/runs/7gq9wv1o\" target=\"_blank\">https://wandb.ai/umass-iesl-is/cs685-project/runs/7gq9wv1o</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20220511_234515-7gq9wv1o/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Run 7gq9wv1o errored: ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 7gq9wv1o errored: ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')\n"]}]},{"cell_type":"code","source":["def avg_rec(y_test, y_pred):\n","    rec_n, rec_u, rec_p = recall_score(y_test, y_pred, average=None)\n","    return (1/3) * (rec_n+ rec_u+ rec_p)"],"metadata":{"id":"JmTTwotjUcIY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def f1_np(y_test, y_pred):\n","    f1_n, _,f1_p = f1_score(y_test, y_pred, average=None)\n","    return 0.5*(f1_n+f1_p)"],"metadata":{"id":"_jM0vbyIUeZs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def eval_model(model, data_loader, loss_fn, device, n_examples):\n","  model = model.eval()\n","\n","  losses = []\n","  correct_predictions = 0\n","\n","  with torch.no_grad():\n","    for d in data_loader:\n","      input_ids = d[\"input_ids\"].to(device)\n","      attention_mask = d[\"attention_mask\"].to(device)\n","      targets = d[\"targets\"].to(device)\n","\n","      outputs = model(\n","        input_ids=input_ids,\n","        attention_mask=attention_mask\n","      )\n","      _, preds = torch.max(outputs, dim=1)\n","\n","      loss = loss_fn(outputs, targets)\n","\n","      correct_predictions += torch.sum(preds == targets)\n","      losses.append(loss.item())\n","\n","  return correct_predictions.double() / n_examples, np.mean(losses)"],"metadata":{"id":"jJeS6xbdVkZU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.load_state_dict(torch.load('bertweet_best_model_state.bin'))"],"metadata":{"id":"nXHobQrJWVUU","colab":{"base_uri":"https://localhost:8080/","height":320},"executionInfo":{"status":"error","timestamp":1652312878251,"user_tz":240,"elapsed":389,"user":{"displayName":"Pragya Sarda","userId":"11319887257693684769"}},"outputId":"1e31ace0-339c-4527-967d-0912900b9ce2"},"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-164-d1d9b2c9efb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bertweet_best_model_state.bin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'bertweet_best_model_state.bin'"]}]},{"cell_type":"code","source":["test_acc, _ = eval_model(\n","  model,\n","  validation_dataloader,\n","  loss_fn,\n","  device,\n","  len(df_test)\n",")\n","\n","test_acc.item()"],"metadata":{"id":"a-7Va1gRV435"},"execution_count":null,"outputs":[]}]}