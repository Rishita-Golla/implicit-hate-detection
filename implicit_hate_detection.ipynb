{"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/kimberley-faria/implicit-hate-detection/blob/main/implicit_hate_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"yhfIXiIBYfO9"},"source":["setup a git repo in your google drive - https://medium.com/analytics-vidhya/how-to-use-google-colab-with-github-via-google-drive-68efb23a42d\n","\n","(I did this in a separate notebook, so I can keep this one free of git commit/push etc commands)"]},{"cell_type":"code","source":["# if local\n","# !conda activate cs685"],"metadata":{"id":"1fUCvocV8Wco"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["BASE_PATH = '/content/drive/MyDrive/Github/685/implicit-hate-detection'\n","DATA_PATH = '../data/implicit-hate-corpus-nov-2021/implicit-hate-corpus'"],"metadata":{"id":"8CMaZaGe-ZaD","executionInfo":{"status":"ok","timestamp":1650731475573,"user_tz":240,"elapsed":149,"user":{"displayName":"Kimberley Faria","userId":"05009575160539653667"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["import os\n","import sys\n","os.path.dirname(sys.executable)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Km7BbPyebrnp","executionInfo":{"status":"ok","timestamp":1650731476389,"user_tz":240,"elapsed":163,"user":{"displayName":"Kimberley Faria","userId":"05009575160539653667"}},"outputId":"aaf88962-8de5-4f25-9cbd-0454e4c6892b"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/usr/bin'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["import sys\n","\n","if 'google.colab' in sys.modules:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    base_path = BASE_PATH\n","else:\n","    base_path = r'C:\\Users\\faria\\PycharmProjects\\685\\project\\implicit-hate-detection'"],"metadata":{"id":"TWIj6y_D8wpZ","executionInfo":{"status":"ok","timestamp":1650731582801,"user_tz":240,"elapsed":104473,"user":{"displayName":"Kimberley Faria","userId":"05009575160539653667"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c842e616-1999-4dab-874a-8e38344637bd"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"gMT_aJYbYvrt"},"source":["switch to the git repo in your drive"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7782,"status":"ok","timestamp":1650731841789,"user":{"displayName":"Kimberley Faria","userId":"05009575160539653667"},"user_tz":240},"id":"6ToiwT8GNVS1","outputId":"60892c94-ddb6-464f-923d-0fe298eaa72f"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Github/685/implicit-hate-detection\n","error: Your local changes to the following files would be overwritten by checkout:\n","\timplicit_hate_detection.ipynb\n","Please commit your changes or stash them before you switch branches.\n","Aborting\n"]}],"source":["%cd $base_path\n","!git checkout 2-bert-baselines-bin-classification"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":58,"status":"ok","timestamp":1649612486061,"user":{"displayName":"Kimberley Faria","userId":"05009575160539653667"},"user_tz":240},"id":"kGp_p5xWFLdN","outputId":"069fedfb-7544-4ce3-e42d-896bebc72ebc"},"outputs":[{"output_type":"stream","name":"stdout","text":["On branch 5-bert-baselines-bin-classification-hate-non-hate\n","Your branch is up to date with 'origin/5-bert-baselines-bin-classification-hate-non-hate'.\n","\n","Changes not staged for commit:\n","  (use \"git add <file>...\" to update what will be committed)\n","  (use \"git restore <file>...\" to discard changes in working directory)\n","\tmodified:   requirements.txt\n","\n","no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"]}],"source":["!git status"]},{"cell_type":"markdown","metadata":{"id":"wclElGePY0tZ"},"source":["install requirements from repo "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G8MSToF9QoD5"},"outputs":[],"source":["# for colab, use venv if in local\n","# !pip install -r requirements.txt"]},{"cell_type":"markdown","metadata":{"id":"1hNnkZxzY4jo"},"source":["load the helper and dataloader files"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nWr1Me-jPz2k"},"outputs":[],"source":["%load implicit_hate_dataloader/dataloader.py    \n","%load implicit_hate_dataloader/helpers.py"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2230,"status":"ok","timestamp":1649612491173,"user":{"displayName":"Kimberley Faria","userId":"05009575160539653667"},"user_tz":240},"id":"8q8KN4enRReS","outputId":"bd54ef81-e77f-4edb-e76f-96f160e9b9d9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found device: GeForce GTX 1050 Ti with Max-Q Design, n_gpu: 1\n"]}],"source":["import torch\n","assert torch.cuda.is_available()\n","\n","# Get the GPU device name.\n","device_name = torch.cuda.get_device_name()\n","n_gpu = torch.cuda.device_count()\n","print(f\"Found device: {device_name}, n_gpu: {n_gpu}\")\n","device = torch.device(\"cuda\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"67n093r1R-c4"},"outputs":[],"source":["import os\n","\n","data_path = DATA_PATH\n","dataset_filename = {\n","    # post (str)\n","    # class (str): high-level label in {`explicit_hate`,`implicit_hate`,`not_hate`}\n","    \"stage-1\": os.path.join(data_path, \"implicit_hate_v1_stg1_posts.tsv\"),\n","\n","    # post (str)\n","    # class (str): fine-grained implicit hate label in\n","    # {`white_grievance`, `incitement`, `inferiority`, `irony`, `stereotypical`, `threatening`, `other`}\n","    # extra_implicit_class: (str) A secondary fine-grained implicit hate label in\n","    # {`white_grievance`, `incitement`, `inferiority`, `irony`, `stereotypical`, `threatening`, `other`, **None**}\n","    \"stage-2\": os.path.join(data_path, \"implicit_hate_v1_stg2_posts.tsv\"),\n","\n","    # post (str)\n","    # target: (str) Free-text annotation for the group being targeted (e.g. `Black people`, `Immigrants`, etc.)\n","    # implied_statement: (str) Free-text annotation for the implicit or hidden underlying meaning of the post made\n","    # explicit (e.g. `people in minority groups are all in gangs`)\n","    \"stage-3\": os.path.join(data_path, \"implicit_hate_v1_stg3_posts.tsv\")\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"InLTAsNtScfz"},"outputs":[],"source":["from implicit_hate_dataloader.dataloader import Stage1Dataset, Stage2Dataset\n","from torch.utils.data import DataLoader"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12852,"status":"ok","timestamp":1649612505356,"user":{"displayName":"Kimberley Faria","userId":"05009575160539653667"},"user_tz":240},"id":"oNX3wn10R6_t","outputId":"d35f3716-9f91-4ec4-a8e3-74752d8f195f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset size 21480\n","Dataset splits [12888, 4296, 4296]\n"]}],"source":["# Stage 1 Annotations: see config.py for dataset specs\n","implicit_hate_dataset = Stage1Dataset(dataset_filename[\"stage-1\"], merge_hate_labels=True)\n","\n","dataset_size = len(implicit_hate_dataset)\n","dataset_splits = [int(0.6*dataset_size), int(0.2*dataset_size), dataset_size - int(0.6*dataset_size) - int(0.2*dataset_size)]\n","\n","# # Smaller dataset for testing model\n","# dataset_splits = [int(0.006*dataset_size), int(0.002*dataset_size), int(0.002*dataset_size)]\n","print(\"Dataset size\", dataset_size)\n","print(\"Dataset splits\", dataset_splits)\n","\n","train_set, val_set, test_set = torch.utils.data.random_split(implicit_hate_dataset, dataset_splits)\n","\n","train_dataloader =  DataLoader(train_set, batch_size=8, shuffle=False)\n","validation_dataloader = DataLoader(val_set, batch_size=8, shuffle=False)\n","\n","# assert len(train_set) == int(0.6*dataset_size)\n","# assert len(val_set) == int(0.2*dataset_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1649612505384,"user":{"displayName":"Kimberley Faria","userId":"05009575160539653667"},"user_tz":240},"id":"Zm49lo2jwOEB","outputId":"42342a2c-be98-46e9-e6ef-3fa2728f4591"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'torch.Tensor'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n"]}],"source":["# Confirming type is tensor\n","_, _, input_ids, attention_masks, labels = next(iter(train_dataloader))\n","print(type(input_ids), type(attention_masks), type(labels))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y6DWesKexrLl"},"outputs":[],"source":["from sklearn.metrics import precision_recall_fscore_support\n","\n","import numpy as np\n","# function to get validation accuracy\n","def get_validation_performance(model, val_set, config):\n","    # Put the model in evaluation mode\n","    model.eval()\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","\n","    validation_dataloader = DataLoader(val_set, batch_size=config[\"batch_size\"], shuffle=True)\n","\n","    total_correct = 0\n","\n","    predicted = []\n","    labels = []\n","\n","    for batch in validation_dataloader:\n","\n","      input_id_tensors = batch[2]\n","      input_mask_tensors = batch[3]\n","      label_tensors = batch[4]\n","      \n","      # Move tensors to the GPU\n","      b_input_ids = input_id_tensors.to(device)\n","      b_input_mask = input_mask_tensors.to(device)\n","      b_labels = label_tensors.to(device)\n","        \n","      # Tell pytorch not to bother with constructing the compute graph during\n","      # the forward pass, since this is only needed for backprop (training).\n","      with torch.no_grad():        \n","\n","        # Forward pass, calculate logit predictions.\n","        outputs = model(b_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask,\n","                        labels=b_labels)\n","        loss = outputs.loss\n","        logits = outputs.logits\n","            \n","        # Accumulate the validation loss.\n","        total_eval_loss += loss.item()\n","        \n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the number of correctly labeled examples in batch\n","        pred_flat = np.argmax(logits, axis=1).flatten()\n","        labels_flat = label_ids.flatten()\n","        num_correct = np.sum(pred_flat == labels_flat)\n","        total_correct += num_correct\n","        \n","        predicted.append(pred_flat)\n","        labels.append(labels_flat)      \n","\n","        \n","    predicted = np.concatenate(predicted)\n","    labels = np.concatenate(labels)\n","\n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_correct / len(val_set)\n","    final_score = precision_recall_fscore_support(predicted, labels)\n","\n","    return avg_val_accuracy, final_score"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2660,"status":"ok","timestamp":1649612509066,"user":{"displayName":"Kimberley Faria","userId":"05009575160539653667"},"user_tz":240},"id":"tHIbTaDVDAKM","outputId":"22ab180f-6731-493e-cff5-5566877471db"},"outputs":[{"output_type":"stream","name":"stderr","text":["wandb: Currently logged in as: umass-iesl-is (use `wandb login --relogin` to force relogin)\n"]}],"source":["!wandb login "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1155,"status":"ok","timestamp":1649612510233,"user":{"displayName":"Kimberley Faria","userId":"05009575160539653667"},"user_tz":240},"id":"JePDf44Y8KCx","outputId":"a23c17e5-aacf-413f-9818-069157bb6c50"},"outputs":[{"output_type":"stream","name":"stdout","text":["Create sweep with ID: m5qtc7mz\n","Sweep URL: https://wandb.ai/umass-iesl-is/cs685-project/sweeps/m5qtc7mz\n"]}],"source":["import wandb\n","\n","# sweep_config = {\n","#     \"method\" : \"grid\",\n","#     \"parameters\" : {\n","#         \"batch_size\": {\n","#             \"values\" : [8, 16, 32, 64]\n","#         },\n","#         \"learning_rate\" : {\n","#             \"values\": [2e-5, 3e-5, 5e-5]\n","#         },\n","#         \"epochs\" : {\n","#             \"values\" : [1, 2, 3, 4, 5]\n","#         },\n","#     }\n","# }\n","\n","# hyperparameters used in original paper\n","sweep_config = {\n","    \"name\": \"original-ppr-hparams-sweep\",\n","    \"method\" : \"grid\",\n","    \"parameters\" : {\n","        \"batch_size\": {\n","            \"values\" : [8]\n","        },\n","        \"learning_rate\" : {\n","            \"values\": [2e-5, 3e-5, 5e-5]\n","        },\n","        \"epochs\" : {\n","            \"values\" : [ 2, 3, 4]\n","        },\n","        \"epsilon\": {\n","            \"values\" : [1e-8]\n","        },\n","    }\n","}\n","\n","sweep_id = wandb.sweep(sweep_config, entity=\"umass-iesl-is\", project=\"cs685-project\")\n","# sweep_id = \"gwbynpx8\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xv4NZMApsR88"},"outputs":[],"source":["from transformers import BertForSequenceClassification, AdamW, BertConfig\n","\n","def train():\n","    with wandb.init() as run:\n","        config = wandb.config\n","        \n","        model = BertForSequenceClassification.from_pretrained(\n","        \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n","        num_labels = 2, # The number of output labels.   \n","        output_attentions = False, # Whether the model returns attentions weights.\n","        output_hidden_states = False, # Whether the model returns all hidden-states.\n","        )\n","\n","        # Tell pytorch to run this model on the GPU.\n","        model.cuda()\n","\n","\n","        optimizer = AdamW(model.parameters(),\n","                        lr = config[\"learning_rate\"], # args.learning_rate - default is 5e-5\n","                        eps = config[\"epsilon\"] # args.adam_epsilon  - default is 1e-8\n","                        )\n","        wandb.watch(model, log=\"all\")\n","\n","        for epoch_i in range(0, config[\"epochs\"]):\n","            # Perform one full pass over the training set.\n","\n","            print(\"\")\n","            print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, config[\"epochs\"]))\n","            print('Training...')\n","\n","            # Reset the total loss for this epoch.\n","            total_train_loss = 0\n","\n","            # Put the model into training mode.\n","            model.train()\n","\n","            # For each batch of training data...\n","            train_dataloader =  DataLoader(train_set, batch_size=config[\"batch_size\"], shuffle=False)\n","\n","            for batch_idx, batch in enumerate(train_dataloader):\n","\n","                input_id_tensors = batch[2]\n","                input_mask_tensors = batch[3]\n","                label_tensors = batch[4]\n","\n","                # Move tensors to the GPU\n","                b_input_ids = input_id_tensors.to(device)\n","                b_input_mask = input_mask_tensors.to(device)\n","                b_labels = label_tensors.to(device)\n","\n","                # Clear the previously calculated gradient\n","                model.zero_grad()        \n","\n","                # Perform a forward pass (evaluate the model on this training batch).\n","                outputs = model(b_input_ids, \n","                                token_type_ids=None, \n","                                attention_mask=b_input_mask, \n","                                labels=b_labels)\n","                loss = outputs.loss\n","                logits = outputs.logits\n","\n","                total_train_loss += loss.item()\n","\n","                # Perform a backward pass to calculate the gradients.\n","                loss.backward()\n","\n","                # Update parameters and take a step using the computed gradient.\n","                optimizer.step()\n","                wandb.log({\n","                    \"batch_loss\": loss.item(),\n","                    \"batch\": batch_idx\n","                })\n","                \n","            # ========================================\n","            #               Validation\n","            # ========================================\n","            # After the completion of each training epoch, measure our performance on\n","            # our validation set. Implement this function in the cell above.\n","            print(f\"Total loss: {total_train_loss}\")\n","            val_acc, (val_precision, val_recall, val_f1, val_hash) = get_validation_performance(model, val_set, config)\n","            print(val_precision, val_recall, val_f1)\n","            print(f\"Validation accuracy: {val_acc}\")\n","\n","            wandb.log({\n","                \"loss\": total_train_loss, \n","                \"epoch\": config[\"epochs\"], \n","                \"val_acc\": val_acc,\n","                \"val_precision\": val_precision,\n","                \"val_recall\": val_recall,\n","                \"val_f1\": val_f1\n","                })\n","            \n","        print(\"\")\n","        print(\"Training complete!\")\n","\n","        test_acc, (test_precision, test_recall, test_f1, test_hash) = get_validation_performance(model, test_set, config)\n","        print(test_precision, test_recall, test_f1)\n","        print(f\"Test accuracy: {test_acc}\")\n","        wandb.log({\n","            \"test_acc\": test_acc,\n","            \"test_precision\": test_precision,\n","            \"test_recall\": test_recall,\n","            \"test_f1\": test_f1\n","            })\n","\n","        # torch.save(model.state_dict(), \"model.h5\")\n","        # wandb.save('model.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tijcbxfZJ6M6","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["8a6a4050f6c0454eb5ffd33b8b8e79f3","de08b8c749a4448bb40e744e565a978e","90f4dd58a3fd4ec9a9d84116286c2bf6","c8fb41bc6c4e4a5497300357f3fe0b23","75b44de3023047ae811b0924d75fc7f2","16a89dd8a17b4be491c5735a2ecbbb5e","f5345caed82242288ba2e3df5e4b3a5a","d5483b3b3dca440a8b2ddf311533da80","ac6e0ec218dc41b58841898a6625abac","1364f35ec0104e16b76231574ac20cf1","23db0475bddb4b74b68bcb261f07548f","28b1485055484727912a236f5b9f0dbc","6fa856242f42483eb11ff92cb3eb3dae","ac8af3ba1bc6409aa1efda890c18a8ee","9acb095881ef4ca597b229e5b7ee3254","de26cdc77bb441789e85461016c94d61"]},"outputId":"d9e4cb79-ef34-46cb-c22b-4dbd722267c2","executionInfo":{"status":"ok","timestamp":1649615084112,"user_tz":240,"elapsed":2573845,"user":{"displayName":"Kimberley Faria","userId":"05009575160539653667"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: usor5apu with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepsilon: 1e-08\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mumass-iesl-is\u001b[0m (use `wandb login --relogin` to force relogin)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["wandb version 0.12.14 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.12.11"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>C:\\Users\\faria\\PycharmProjects\\685\\project\\implicit-hate-detection\\wandb\\run-20220410_134151-usor5apu</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/umass-iesl-is/cs685-project/runs/usor5apu\" target=\"_blank\">fancy-sweep-1</a></strong> to <a href=\"https://wandb.ai/umass-iesl-is/cs685-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/umass-iesl-is/cs685-project/sweeps/m5qtc7mz\" target=\"_blank\">https://wandb.ai/umass-iesl-is/cs685-project/sweeps/m5qtc7mz</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","C:\\Users\\faria\\anaconda3\\envs\\cs685\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","======== Epoch 1 / 2 ========\n","Training...\n","Total loss: 831.9519884809852\n","[0.75903166 0.79577902] [0.86100549 0.66459305] [0.80680918 0.72429379]\n","Validation accuracy: 0.7728119180633147\n","\n","======== Epoch 2 / 2 ========\n","Training...\n","Total loss: 541.3521888926625\n","[0.79068901 0.73929236] [0.83484074 0.67940673] [0.81216526 0.70808561]\n","Validation accuracy: 0.771415270018622\n","\n","Training complete!\n","[0.79772296 0.72847682] [0.82334508 0.69420539] [0.81033153 0.71092832]\n","Test accuracy: 0.770949720670391\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a6a4050f6c0454eb5ffd33b8b8e79f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>▁▁▂▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇▇█▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▆▇▇██</td></tr><tr><td>batch_loss</td><td>▇█▄▅▅▄█▇▇▆▄▃▆▅▇▆▇▃▃▇█▆▃▃▆▅▁▄▃▃▁▂▂▄▃▆▆▃▃▁</td></tr><tr><td>epoch</td><td>▁▁</td></tr><tr><td>loss</td><td>█▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>val_acc</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>1610</td></tr><tr><td>batch_loss</td><td>0.12854</td></tr><tr><td>epoch</td><td>2</td></tr><tr><td>loss</td><td>541.35219</td></tr><tr><td>test_acc</td><td>0.77095</td></tr><tr><td>val_acc</td><td>0.77142</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Synced <strong style=\"color:#cdcd00\">fancy-sweep-1</strong>: <a href=\"https://wandb.ai/umass-iesl-is/cs685-project/runs/usor5apu\" target=\"_blank\">https://wandb.ai/umass-iesl-is/cs685-project/runs/usor5apu</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>.\\wandb\\run-20220410_134151-usor5apu\\logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yvp1lqpn with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepsilon: 1e-08\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3e-05\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["wandb version 0.12.14 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.12.11"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>C:\\Users\\faria\\PycharmProjects\\685\\project\\implicit-hate-detection\\wandb\\run-20220410_140330-yvp1lqpn</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/umass-iesl-is/cs685-project/runs/yvp1lqpn\" target=\"_blank\">frosty-sweep-2</a></strong> to <a href=\"https://wandb.ai/umass-iesl-is/cs685-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/umass-iesl-is/cs685-project/sweeps/m5qtc7mz\" target=\"_blank\">https://wandb.ai/umass-iesl-is/cs685-project/sweeps/m5qtc7mz</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","C:\\Users\\faria\\anaconda3\\envs\\cs685\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","======== Epoch 1 / 2 ========\n","Training...\n","Total loss: 840.3514669835567\n","[0.80372439 0.73929236] [0.83708301 0.69324796] [0.8200646  0.71553019]\n","Validation accuracy: 0.779562383612663\n","\n","======== Epoch 2 / 2 ========\n","Training...\n","Total loss: 568.0989641286433\n","[0.75493482 0.7839851 ] [0.85347368 0.65747007] [0.80118577 0.71517554]\n","Validation accuracy: 0.765828677839851\n","\n","Training complete!\n","[0.76242884 0.782059  ] [0.84732181 0.67480519] [0.80263684 0.7244841 ]\n","Test accuracy: 0.7700186219739292\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac6e0ec218dc41b58841898a6625abac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>▁▁▂▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇▇█▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▆▇▇██</td></tr><tr><td>batch_loss</td><td>▇█▅▆▇▄█▅▇▅▅▂▅▆█▇▇▃▃█▇▅▃▃▄▄▂▅▅▂▁▃▅▅▃▃▆▄▃▁</td></tr><tr><td>epoch</td><td>▁▁</td></tr><tr><td>loss</td><td>█▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>val_acc</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>1610</td></tr><tr><td>batch_loss</td><td>0.35284</td></tr><tr><td>epoch</td><td>2</td></tr><tr><td>loss</td><td>568.09896</td></tr><tr><td>test_acc</td><td>0.77002</td></tr><tr><td>val_acc</td><td>0.76583</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Synced <strong style=\"color:#cdcd00\">frosty-sweep-2</strong>: <a href=\"https://wandb.ai/umass-iesl-is/cs685-project/runs/yvp1lqpn\" target=\"_blank\">https://wandb.ai/umass-iesl-is/cs685-project/runs/yvp1lqpn</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>.\\wandb\\run-20220410_140330-yvp1lqpn\\logs</code>"]},"metadata":{}}],"source":["count = 2 # number of runs to execute\n","wandb.agent(sweep_id, function=train, count=count, entity=\"umass-iesl-is\", project=\"cs685-project\")"]}],"metadata":{"accelerator":"GPU","colab":{"name":"implicit_hate_detection.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"8a6a4050f6c0454eb5ffd33b8b8e79f3":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_de08b8c749a4448bb40e744e565a978e","IPY_MODEL_90f4dd58a3fd4ec9a9d84116286c2bf6"],"layout":"IPY_MODEL_c8fb41bc6c4e4a5497300357f3fe0b23"}},"de08b8c749a4448bb40e744e565a978e":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_75b44de3023047ae811b0924d75fc7f2","placeholder":"​","style":"IPY_MODEL_16a89dd8a17b4be491c5735a2ecbbb5e","value":"0.755 MB of 0.755 MB uploaded (0.000 MB deduped)\r"}},"90f4dd58a3fd4ec9a9d84116286c2bf6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5345caed82242288ba2e3df5e4b3a5a","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d5483b3b3dca440a8b2ddf311533da80","value":1}},"c8fb41bc6c4e4a5497300357f3fe0b23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75b44de3023047ae811b0924d75fc7f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16a89dd8a17b4be491c5735a2ecbbb5e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f5345caed82242288ba2e3df5e4b3a5a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5483b3b3dca440a8b2ddf311533da80":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ac6e0ec218dc41b58841898a6625abac":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_1364f35ec0104e16b76231574ac20cf1","IPY_MODEL_23db0475bddb4b74b68bcb261f07548f"],"layout":"IPY_MODEL_28b1485055484727912a236f5b9f0dbc"}},"1364f35ec0104e16b76231574ac20cf1":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6fa856242f42483eb11ff92cb3eb3dae","placeholder":"​","style":"IPY_MODEL_ac8af3ba1bc6409aa1efda890c18a8ee","value":"0.753 MB of 0.753 MB uploaded (0.000 MB deduped)\r"}},"23db0475bddb4b74b68bcb261f07548f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_9acb095881ef4ca597b229e5b7ee3254","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_de26cdc77bb441789e85461016c94d61","value":1}},"28b1485055484727912a236f5b9f0dbc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6fa856242f42483eb11ff92cb3eb3dae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac8af3ba1bc6409aa1efda890c18a8ee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9acb095881ef4ca597b229e5b7ee3254":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de26cdc77bb441789e85461016c94d61":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":0}