{"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/kimberley-faria/implicit-hate-detection/blob/main/implicit_hate_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"yhfIXiIBYfO9"},"source":["setup a git repo in your google drive - https://medium.com/analytics-vidhya/how-to-use-google-colab-with-github-via-google-drive-68efb23a42d\n","\n","(I did this in a separate notebook, so I can keep this one free of git commit/push etc commands)"]},{"cell_type":"code","source":["# if local\n","!conda activate cs685"],"metadata":{"id":"1fUCvocV8Wco","executionInfo":{"status":"ok","timestamp":1649127590336,"user_tz":240,"elapsed":472,"user":{"displayName":"Kimberley Faria","userId":"05009575160539653667"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["import os\n","import sys\n","os.path.dirname(sys.executable)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Km7BbPyebrnp","executionInfo":{"status":"ok","timestamp":1649127590353,"user_tz":240,"elapsed":15,"user":{"displayName":"Kimberley Faria","userId":"05009575160539653667"}},"outputId":"caf344b1-db21-49fd-ec33-efd03f2768f1"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'C:\\\\Users\\\\faria\\\\anaconda3\\\\envs\\\\cs685'"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["import sys\n","\n","if 'google.colab' in sys.modules:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    base_path = '/content/drive/MyDrive/Github/685/implicit-hate-detection'\n","else:\n","    base_path = r'C:\\Users\\faria\\PycharmProjects\\685\\project\\implicit-hate-detection'"],"metadata":{"id":"TWIj6y_D8wpZ","executionInfo":{"status":"ok","timestamp":1649127591108,"user_tz":240,"elapsed":25,"user":{"displayName":"Kimberley Faria","userId":"05009575160539653667"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gMT_aJYbYvrt"},"source":["switch to the git repo in your drive"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":71,"status":"ok","timestamp":1649127592278,"user":{"displayName":"Kimberley Faria","userId":"05009575160539653667"},"user_tz":240},"id":"6ToiwT8GNVS1","outputId":"22423f22-38cc-43cb-e65b-e369453e4f6a"},"outputs":[{"output_type":"stream","name":"stdout","text":["C:\\Users\\faria\\PycharmProjects\\685\\project\\implicit-hate-detection\n"]},{"output_type":"stream","name":"stderr","text":["Already on '2-bert-baselines-bin-classification'\n"]},{"output_type":"stream","name":"stdout","text":["Your branch is up to date with 'origin/2-bert-baselines-bin-classification'.\n"]}],"source":["%cd $base_path\n","!git checkout 2-bert-baselines-bin-classification"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":85,"status":"ok","timestamp":1649127593086,"user":{"displayName":"Kimberley Faria","userId":"05009575160539653667"},"user_tz":240},"id":"kGp_p5xWFLdN","outputId":"a2687c50-4992-43cf-b87d-5e0cb1192a5e"},"outputs":[{"output_type":"stream","name":"stdout","text":["On branch 2-bert-baselines-bin-classification\n","Your branch is up to date with 'origin/2-bert-baselines-bin-classification'.\n","\n","nothing to commit, working tree clean\n"]}],"source":["!git status"]},{"cell_type":"markdown","metadata":{"id":"wclElGePY0tZ"},"source":["install requirements from repo "]},{"cell_type":"code","execution_count":6,"metadata":{"id":"G8MSToF9QoD5","executionInfo":{"status":"ok","timestamp":1649127594291,"user_tz":240,"elapsed":4,"user":{"displayName":"Kimberley Faria","userId":"05009575160539653667"}}},"outputs":[],"source":["# for colab, use venv if in local\n","# !pip install -r requirements.txt"]},{"cell_type":"markdown","metadata":{"id":"1hNnkZxzY4jo"},"source":["load the helper and dataloader files"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1649127595936,"user":{"displayName":"Kimberley Faria","userId":"05009575160539653667"},"user_tz":240},"id":"nWr1Me-jPz2k"},"outputs":[],"source":["%load implicit_hate_dataloader/dataloader.py    \n","%load implicit_hate_dataloader/helpers.py"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1810,"status":"ok","timestamp":1649127604151,"user":{"displayName":"Kimberley Faria","userId":"05009575160539653667"},"user_tz":240},"id":"8q8KN4enRReS","outputId":"c2a8fb17-186d-4dfd-e7a8-92d935c449df"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found device: GeForce GTX 1050 Ti with Max-Q Design, n_gpu: 1\n"]}],"source":["import torch\n","assert torch.cuda.is_available()\n","\n","# Get the GPU device name.\n","device_name = torch.cuda.get_device_name()\n","n_gpu = torch.cuda.device_count()\n","print(f\"Found device: {device_name}, n_gpu: {n_gpu}\")\n","device = torch.device(\"cuda\")"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1649127605388,"user":{"displayName":"Kimberley Faria","userId":"05009575160539653667"},"user_tz":240},"id":"67n093r1R-c4"},"outputs":[],"source":["import os\n","\n","data_path = '../data/implicit-hate-corpus-nov-2021/implicit-hate-corpus'\n","dataset_filename = {\n","    # post (str)\n","    # class (str): high-level label in {`explicit_hate`,`implicit_hate`,`not_hate`}\n","    \"stage-1\": os.path.join(data_path, \"implicit_hate_v1_stg1_posts.tsv\"),\n","\n","    # post (str)\n","    # class (str): fine-grained implicit hate label in\n","    # {`white_grievance`, `incitement`, `inferiority`, `irony`, `stereotypical`, `threatening`, `other`}\n","    # extra_implicit_class: (str) A secondary fine-grained implicit hate label in\n","    # {`white_grievance`, `incitement`, `inferiority`, `irony`, `stereotypical`, `threatening`, `other`, **None**}\n","    \"stage-2\": os.path.join(data_path, \"implicit_hate_v1_stg2_posts.tsv\"),\n","\n","    # post (str)\n","    # target: (str) Free-text annotation for the group being targeted (e.g. `Black people`, `Immigrants`, etc.)\n","    # implied_statement: (str) Free-text annotation for the implicit or hidden underlying meaning of the post made\n","    # explicit (e.g. `people in minority groups are all in gangs`)\n","    \"stage-3\": os.path.join(data_path, \"implicit_hate_v1_stg3_posts.tsv\")\n","}"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":917,"status":"ok","timestamp":1649127608719,"user":{"displayName":"Kimberley Faria","userId":"05009575160539653667"},"user_tz":240},"id":"InLTAsNtScfz"},"outputs":[],"source":["from implicit_hate_dataloader.dataloader import Stage1Dataset, Stage2Dataset\n","from torch.utils.data import DataLoader"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11745,"status":"ok","timestamp":1649127620667,"user":{"displayName":"Kimberley Faria","userId":"05009575160539653667"},"user_tz":240},"id":"oNX3wn10R6_t","outputId":"40f504bd-ba65-4f60-b4eb-e8638056fd4d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset size 21480\n","Dataset splits [12888, 4296, 4296]\n"]}],"source":["# Stage 1 Annotations: see config.py for dataset specs\n","implicit_hate_dataset = Stage1Dataset(dataset_filename[\"stage-1\"])\n","\n","dataset_size = len(implicit_hate_dataset)\n","dataset_splits = [int(0.6*dataset_size), int(0.2*dataset_size), int(0.2*dataset_size)]\n","\n","# # Smaller dataset for testing model\n","# dataset_splits = [int(0.006*dataset_size), int(0.002*dataset_size), int(0.002*dataset_size)]\n","print(\"Dataset size\", dataset_size)\n","print(\"Dataset splits\", dataset_splits)\n","\n","train_set, val_set, test_set = torch.utils.data.random_split(implicit_hate_dataset, [int(0.6*dataset_size), int(0.2*dataset_size), int(0.2*dataset_size)])\n","\n","train_dataloader =  DataLoader(train_set, batch_size=4, shuffle=False)\n","validation_dataloader = DataLoader(val_set, batch_size=4, shuffle=False)\n","\n","assert len(train_set) == int(0.6*dataset_size)\n","assert len(val_set) == int(0.2*dataset_size)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1649127620673,"user":{"displayName":"Kimberley Faria","userId":"05009575160539653667"},"user_tz":240},"id":"Zm49lo2jwOEB","outputId":"dc4e1cd2-0f08-4570-f80c-a927ca2d850e"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'torch.Tensor'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n"]}],"source":["# Confirming type is tensor\n","_, _, input_ids, attention_masks, labels = next(iter(train_dataloader))\n","print(type(input_ids), type(attention_masks), type(labels))"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1649127620690,"user":{"displayName":"Kimberley Faria","userId":"05009575160539653667"},"user_tz":240},"id":"y6DWesKexrLl"},"outputs":[],"source":["import numpy as np\n","# function to get validation accuracy\n","def get_validation_performance(model, val_set, config):\n","    # Put the model in evaluation mode\n","    model.eval()\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","\n","    validation_dataloader = DataLoader(val_set, batch_size=config[\"batch_size\"], shuffle=True)\n","\n","    total_correct = 0\n","\n","    for batch in validation_dataloader:\n","\n","      input_id_tensors = batch[2]\n","      input_mask_tensors = batch[3]\n","      label_tensors = batch[4]\n","      \n","      # Move tensors to the GPU\n","      b_input_ids = input_id_tensors.to(device)\n","      b_input_mask = input_mask_tensors.to(device)\n","      b_labels = label_tensors.to(device)\n","        \n","      # Tell pytorch not to bother with constructing the compute graph during\n","      # the forward pass, since this is only needed for backprop (training).\n","      with torch.no_grad():        \n","\n","        # Forward pass, calculate logit predictions.\n","        outputs = model(b_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask,\n","                        labels=b_labels)\n","        loss = outputs.loss\n","        logits = outputs.logits\n","            \n","        # Accumulate the validation loss.\n","        total_eval_loss += loss.item()\n","        \n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the number of correctly labeled examples in batch\n","        pred_flat = np.argmax(logits, axis=1).flatten()\n","        labels_flat = label_ids.flatten()\n","        num_correct = np.sum(pred_flat == labels_flat)\n","        total_correct += num_correct\n","        \n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_correct / len(val_set)\n","    return avg_val_accuracy"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2160,"status":"ok","timestamp":1649127622863,"user":{"displayName":"Kimberley Faria","userId":"05009575160539653667"},"user_tz":240},"id":"tHIbTaDVDAKM","outputId":"c507eede-5d15-49b2-f7dc-50a48e55c1da"},"outputs":[{"output_type":"stream","name":"stderr","text":["wandb: Currently logged in as: umass-iesl-is (use `wandb login --relogin` to force relogin)\n"]}],"source":["!wandb login "]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2551,"status":"ok","timestamp":1649127631015,"user":{"displayName":"Kimberley Faria","userId":"05009575160539653667"},"user_tz":240},"id":"JePDf44Y8KCx","outputId":"1dea59fe-3e64-45d8-ca95-1ec8a3736b57"},"outputs":[{"output_type":"stream","name":"stdout","text":["Create sweep with ID: y07g3mdm\n","Sweep URL: https://wandb.ai/umass-iesl-is/cs685-project/sweeps/y07g3mdm\n"]}],"source":["import wandb\n","\n","# sweep_config = {\n","#     \"method\" : \"grid\",\n","#     \"parameters\" : {\n","#         \"batch_size\": {\n","#             \"values\" : [8, 16, 32, 64]\n","#         },\n","#         \"learning_rate\" : {\n","#             \"values\": [2e-5, 3e-5, 5e-5]\n","#         },\n","#         \"epochs\" : {\n","#             \"values\" : [1, 2, 3, 4, 5]\n","#         },\n","#     }\n","# }\n","\n","# hyperparameters used in original paper\n","sweep_config = {\n","    \"name\": \"original-ppr-hparams-sweep\",\n","    \"method\" : \"grid\",\n","    \"parameters\" : {\n","        \"batch_size\": {\n","            \"values\" : [8]\n","        },\n","        \"learning_rate\" : {\n","            \"values\": [2e-5, 3e-5, 5e-5]\n","        },\n","        \"epochs\" : {\n","            \"values\" : [1, 2, 3, 4]\n","        },\n","        \"epsilon\": {\n","            \"values\" : [1e-8]\n","        },\n","    }\n","}\n","\n","sweep_id = wandb.sweep(sweep_config, entity=\"umass-iesl-is\", project=\"cs685-project\")"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"xv4NZMApsR88","executionInfo":{"status":"ok","timestamp":1649127631035,"user_tz":240,"elapsed":13,"user":{"displayName":"Kimberley Faria","userId":"05009575160539653667"}}},"outputs":[],"source":["from transformers import BertForSequenceClassification, AdamW, BertConfig\n","\n","def train():\n","    with wandb.init() as run:\n","        config = wandb.config\n","        \n","        model = BertForSequenceClassification.from_pretrained(\n","        \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n","        num_labels = 3, # The number of output labels.   \n","        output_attentions = False, # Whether the model returns attentions weights.\n","        output_hidden_states = False, # Whether the model returns all hidden-states.\n","        )\n","\n","        # Tell pytorch to run this model on the GPU.\n","        model.cuda()\n","\n","\n","        optimizer = AdamW(model.parameters(),\n","                        lr = config[\"learning_rate\"], # args.learning_rate - default is 5e-5\n","                        eps = config[\"epsilon\"] # args.adam_epsilon  - default is 1e-8\n","                        )\n","        wandb.watch(model, log=\"all\")\n","\n","\n","        for epoch_i in range(0, config[\"epochs\"]):\n","            # Perform one full pass over the training set.\n","\n","            print(\"\")\n","            print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, config[\"epochs\"]))\n","            print('Training...')\n","\n","            # Reset the total loss for this epoch.\n","            total_train_loss = 0\n","\n","            # Put the model into training mode.\n","            model.train()\n","\n","            # For each batch of training data...\n","            train_dataloader =  DataLoader(train_set, batch_size=config[\"batch_size\"], shuffle=False)\n","\n","            for batch_idx, batch in enumerate(train_dataloader):\n","\n","                input_id_tensors = batch[2]\n","                input_mask_tensors = batch[3]\n","                label_tensors = batch[4]\n","\n","                # Move tensors to the GPU\n","                b_input_ids = input_id_tensors.to(device)\n","                b_input_mask = input_mask_tensors.to(device)\n","                b_labels = label_tensors.to(device)\n","\n","                # Clear the previously calculated gradient\n","                model.zero_grad()        \n","\n","                # Perform a forward pass (evaluate the model on this training batch).\n","                outputs = model(b_input_ids, \n","                                token_type_ids=None, \n","                                attention_mask=b_input_mask, \n","                                labels=b_labels)\n","                loss = outputs.loss\n","                logits = outputs.logits\n","\n","                total_train_loss += loss.item()\n","\n","                # Perform a backward pass to calculate the gradients.\n","                loss.backward()\n","\n","                # Update parameters and take a step using the computed gradient.\n","                optimizer.step()\n","                wandb.log({\n","                    \"batch_loss\": loss.item(),\n","                    \"batch\": batch_idx\n","                })\n","                \n","            # ========================================\n","            #               Validation\n","            # ========================================\n","            # After the completion of each training epoch, measure our performance on\n","            # our validation set. Implement this function in the cell above.\n","            print(f\"Total loss: {total_train_loss}\")\n","            val_acc = get_validation_performance(model, val_set, config)\n","            print(f\"Validation accuracy: {val_acc}\")\n","            wandb.log({\n","                \"loss\": total_train_loss, \n","                \"epoch\": config[\"epochs\"], \n","                \"val_acc\": val_acc\n","                })\n","            \n","        print(\"\")\n","        print(\"Training complete!\")\n","\n","        test_acc = get_validation_performance(model, test_set, config)\n","        print(f\"Test accuracy: {test_acc}\")\n","        wandb.log({\"test_acc\": test_acc})\n","\n","        # torch.save(model.state_dict(), \"model.h5\")\n","        # wandb.save('model.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tijcbxfZJ6M6","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["c675f8356ec542b2a2d00ba4a99f4319","5322f8663cbd402d8320309dd9303ee6","2822e577234b409b831c83de19c711a0","0db8650a090c4c1e9429a5fcd9fda1c1","29f3aeb410714334ae0bb65ef9d4f1c3","531f9acd2ceb404db7869a2032b1cd64","20078bea8e7045ab9d38422fed231476","01c01a07f4994c10b1c16533d2aabc53"]},"outputId":"846bfce3-61f5-436d-ec86-c951bfcfa6c2"},"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wn810j5r with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepsilon: 1e-08\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mumass-iesl-is\u001b[0m (use `wandb login --relogin` to force relogin)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.12.11"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>C:\\Users\\faria\\PycharmProjects\\685\\project\\implicit-hate-detection\\wandb\\run-20220404_230037-wn810j5r</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/umass-iesl-is/cs685-project/runs/wn810j5r\" target=\"_blank\">volcanic-sweep-1</a></strong> to <a href=\"https://wandb.ai/umass-iesl-is/cs685-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/umass-iesl-is/cs685-project/sweeps/y07g3mdm\" target=\"_blank\">https://wandb.ai/umass-iesl-is/cs685-project/sweeps/y07g3mdm</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","C:\\Users\\faria\\anaconda3\\envs\\cs685\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","======== Epoch 1 / 1 ========\n","Training...\n","Total loss: 1045.6013118550181\n","Validation accuracy: 0.7355679702048417\n","\n","Training complete!\n","Test accuracy: 0.7360335195530726\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c675f8356ec542b2a2d00ba4a99f4319"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch_loss</td><td>▄▄▃▃▄▃▅▄▃▂▂▅▃▂▄▂▂▂▄▃▂▂▃▃▄▂▂▁▃▄▃▂▅▂▃▂▁▂▃█</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>val_acc</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>1610</td></tr><tr><td>batch_loss</td><td>1.01658</td></tr><tr><td>epoch</td><td>1</td></tr><tr><td>loss</td><td>1045.60131</td></tr><tr><td>test_acc</td><td>0.73603</td></tr><tr><td>val_acc</td><td>0.73557</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Synced <strong style=\"color:#cdcd00\">volcanic-sweep-1</strong>: <a href=\"https://wandb.ai/umass-iesl-is/cs685-project/runs/wn810j5r\" target=\"_blank\">https://wandb.ai/umass-iesl-is/cs685-project/runs/wn810j5r</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>.\\wandb\\run-20220404_230037-wn810j5r\\logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rmeh976u with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepsilon: 1e-08\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3e-05\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.12.11"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>C:\\Users\\faria\\PycharmProjects\\685\\project\\implicit-hate-detection\\wandb\\run-20220404_231150-rmeh976u</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/umass-iesl-is/cs685-project/runs/rmeh976u\" target=\"_blank\">zesty-sweep-2</a></strong> to <a href=\"https://wandb.ai/umass-iesl-is/cs685-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/umass-iesl-is/cs685-project/sweeps/y07g3mdm\" target=\"_blank\">https://wandb.ai/umass-iesl-is/cs685-project/sweeps/y07g3mdm</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["\n","======== Epoch 1 / 1 ========\n","Training...\n","Total loss: 1048.2568621188402\n","Validation accuracy: 0.7299813780260708\n","\n","Training complete!\n","Test accuracy: 0.7288175046554934\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}}],"source":["count = 12 # number of runs to execute\n","wandb.agent(sweep_id, function=train, count=count, entity=\"umass-iesl-is\", project=\"cs685-project\")"]}],"metadata":{"accelerator":"GPU","colab":{"name":"implicit_hate_detection.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"c675f8356ec542b2a2d00ba4a99f4319":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_5322f8663cbd402d8320309dd9303ee6","IPY_MODEL_2822e577234b409b831c83de19c711a0"],"layout":"IPY_MODEL_0db8650a090c4c1e9429a5fcd9fda1c1"}},"5322f8663cbd402d8320309dd9303ee6":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_29f3aeb410714334ae0bb65ef9d4f1c3","placeholder":"​","style":"IPY_MODEL_531f9acd2ceb404db7869a2032b1cd64","value":"0.750 MB of 0.750 MB uploaded (0.000 MB deduped)\r"}},"2822e577234b409b831c83de19c711a0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_20078bea8e7045ab9d38422fed231476","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_01c01a07f4994c10b1c16533d2aabc53","value":1}},"0db8650a090c4c1e9429a5fcd9fda1c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29f3aeb410714334ae0bb65ef9d4f1c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"531f9acd2ceb404db7869a2032b1cd64":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"20078bea8e7045ab9d38422fed231476":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01c01a07f4994c10b1c16533d2aabc53":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":0}