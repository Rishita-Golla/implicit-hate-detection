{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERTweet_model-hate vs nonhate.ipynb","provenance":[{"file_id":"1k8i27Fn4GgGtGKNjiCI6lvMrPQuiOGbb","timestamp":1652154603028},{"file_id":"1exS_zcbdHdxKd4aQyn4QSWKag-1_zBIh","timestamp":1652153619919}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"7a5e4fd113704d8a834454f1204961ce":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a6c8474ecf7348c681b1360c0c7958e4","IPY_MODEL_fe098fbd22bb41a998e4639330340d65","IPY_MODEL_c55a2fe024c3426e947edfda29d0f53f"],"layout":"IPY_MODEL_792d4ce519a4495486a2542eab374a1e"}},"a6c8474ecf7348c681b1360c0c7958e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef40a34fe1854bf88542fc6d0e0a2f3a","placeholder":"​","style":"IPY_MODEL_7534892edb1b4508a498372c54bb5829","value":"Downloading: 100%"}},"fe098fbd22bb41a998e4639330340d65":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_499f21441f324aeb987aba045d3f3eeb","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_23b82d2586364ac5bb84a9decd43e1bc","value":231508}},"c55a2fe024c3426e947edfda29d0f53f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_72a7514489174775a69951a11e2e8915","placeholder":"​","style":"IPY_MODEL_ee36e7028dc445a095be3b5359669eac","value":" 226k/226k [00:00&lt;00:00, 329kB/s]"}},"792d4ce519a4495486a2542eab374a1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef40a34fe1854bf88542fc6d0e0a2f3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7534892edb1b4508a498372c54bb5829":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"499f21441f324aeb987aba045d3f3eeb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23b82d2586364ac5bb84a9decd43e1bc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"72a7514489174775a69951a11e2e8915":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee36e7028dc445a095be3b5359669eac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0fd7f98c68694cb1adc98b13f448b3f3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3ca1686d07304ca9ab04fa86f0738a7c","IPY_MODEL_2dbcce59ac4448d0abacf1f4a3e043b0","IPY_MODEL_585283f9873f4d56bcb1a0e36c215a01"],"layout":"IPY_MODEL_95a07eb2009e433a9bca4bd1af30204f"}},"3ca1686d07304ca9ab04fa86f0738a7c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8675cd5ac144da1bfa53b9a5db0c240","placeholder":"​","style":"IPY_MODEL_d26a811fc3794b56ac582a05de93aeb9","value":"Downloading: 100%"}},"2dbcce59ac4448d0abacf1f4a3e043b0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f0c74b96df6c40fc81083b55f4f14e19","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_17785e3089eb4c11b8747a42e45c9c06","value":28}},"585283f9873f4d56bcb1a0e36c215a01":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7944d7e4d2fa46d1a9330a0e4db8364c","placeholder":"​","style":"IPY_MODEL_5732d44cb6d541baaeb7501d13a51563","value":" 28.0/28.0 [00:00&lt;00:00, 837B/s]"}},"95a07eb2009e433a9bca4bd1af30204f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8675cd5ac144da1bfa53b9a5db0c240":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d26a811fc3794b56ac582a05de93aeb9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f0c74b96df6c40fc81083b55f4f14e19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17785e3089eb4c11b8747a42e45c9c06":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7944d7e4d2fa46d1a9330a0e4db8364c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5732d44cb6d541baaeb7501d13a51563":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"764944af5216487b98a0ec6b08fd0fbd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3fe8b72dba5043568433ba55285210b0","IPY_MODEL_74842485987d427da12b04e35ad5310a","IPY_MODEL_fb9339c45d734b6e88f5498b3faeb4aa"],"layout":"IPY_MODEL_f1bdbfc634684c3bb7b84e4153e9794a"}},"3fe8b72dba5043568433ba55285210b0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_77602842054d4cb09d677b533c78b9d0","placeholder":"​","style":"IPY_MODEL_b77236719bb5453482ab752593e9e6b1","value":"Downloading: 100%"}},"74842485987d427da12b04e35ad5310a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc3823fb624b4b5cbb790daa658ea3ea","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8dbd7fffe42044cbaa3015c105ddc794","value":570}},"fb9339c45d734b6e88f5498b3faeb4aa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7087f4231c664ed39fa60de279b59c6a","placeholder":"​","style":"IPY_MODEL_5dafd8cd09404578a3411b638b588a9d","value":" 570/570 [00:00&lt;00:00, 17.7kB/s]"}},"f1bdbfc634684c3bb7b84e4153e9794a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77602842054d4cb09d677b533c78b9d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b77236719bb5453482ab752593e9e6b1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fc3823fb624b4b5cbb790daa658ea3ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8dbd7fffe42044cbaa3015c105ddc794":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7087f4231c664ed39fa60de279b59c6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5dafd8cd09404578a3411b638b588a9d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e12a6882b36f41538f9d5be64568f594":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_556292591616463c87c50e0619139d0b","IPY_MODEL_b871ddd7bfb74843b49f79c8f98922ee"],"layout":"IPY_MODEL_8d9f88b576234af89d574b875c11197b"}},"556292591616463c87c50e0619139d0b":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_545105eb33d44b0a823aea304d4f1c99","placeholder":"​","style":"IPY_MODEL_933ad9befbbf47e889468affed686e98","value":"0.853 MB of 0.853 MB uploaded (0.000 MB deduped)\r"}},"b871ddd7bfb74843b49f79c8f98922ee":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_86e43d01687b483992ca680f3b5c0aa7","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6845376d56b64c03b8e51e1daab15c9a","value":1}},"8d9f88b576234af89d574b875c11197b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"545105eb33d44b0a823aea304d4f1c99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"933ad9befbbf47e889468affed686e98":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"86e43d01687b483992ca680f3b5c0aa7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6845376d56b64c03b8e51e1daab15c9a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"kvf7fqACrBnE","colab":{"base_uri":"https://localhost:8080/"},"outputId":"45749d3b-265c-4f91-af37-7a8150dd8128","executionInfo":{"status":"ok","timestamp":1652154104994,"user_tz":240,"elapsed":14288,"user":{"displayName":"Kimberley Faria","userId":"14997609029817023442"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n","\u001b[K     |████████████████████████████████| 4.0 MB 4.4 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 48.0 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n","\u001b[K     |████████████████████████████████| 77 kB 7.2 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 63.0 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 52.6 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=8ff64d0d46b3ed2837a09c7edf2ca57056aa92a2628afdca60d300e1beeae1b3\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built sacremoses\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0\n"]}],"source":["!pip install transformers, emoji, wandb"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"LT-_TvDtcwlQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652154128888,"user_tz":240,"elapsed":23899,"user":{"displayName":"Kimberley Faria","userId":"14997609029817023442"}},"outputId":"e703fbc9-6216-4e6b-b081-94ced18bec04"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/685-NLP-Project/implicit-hate-detection"],"metadata":{"id":"ue1u7KDAwxLJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652154129214,"user_tz":240,"elapsed":335,"user":{"displayName":"Kimberley Faria","userId":"14997609029817023442"}},"outputId":"56b2a897-533b-4e1a-89a6-678ba093ef54"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1S8UITZ4wcfheudaDPm55HK4b4g-PPNuD/685-NLP-Project/implicit-hate-detection\n"]}]},{"cell_type":"code","source":["!pwd"],"metadata":{"id":"lCrHMiPUsddU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652154129602,"user_tz":240,"elapsed":390,"user":{"displayName":"Kimberley Faria","userId":"14997609029817023442"}},"outputId":"2d60671c-d36d-4506-a691-51d7daa7de8e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1S8UITZ4wcfheudaDPm55HK4b4g-PPNuD/685-NLP-Project/implicit-hate-detection\n"]}]},{"cell_type":"code","source":["%ls -a"],"metadata":{"id":"eXGF0IvQxjic","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652154130527,"user_tz":240,"elapsed":942,"user":{"displayName":"Kimberley Faria","userId":"14997609029817023442"}},"outputId":"066fa6dd-22db-4a5b-ce92-5e9222e5759c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" Anaconda3-5.1.0-Linux-x86_64.sh\n","'Copy of implicit_hate_detection_multi_class.ipynb'\n"," \u001b[0m\u001b[01;34m.git\u001b[0m/\n"," .gitignore\n"," hsol_final_model.bin\n","'HSOL implicit_hate_detection_multi_class.ipynb'\n"," \u001b[01;34mimplicit_hate_dataloader\u001b[0m/\n"," implicit_hate_detection_hate_vs_non_hate.ipynb\n"," implicit_hate_detection_implicit_hate_vs_non_hate.ipynb\n"," implicit_hate_detection.ipynb\n"," implicit_hate_detection_multi_class.ipynb\n"," implicit_hate_detection_multi.ipynb\n"," model.h5\n"," README.md\n"," req_instructions.md\n"," requirements.txt\n"," \u001b[01;34mwandb\u001b[0m/\n"]}]},{"cell_type":"code","source":["import sys\n","\n","if 'google.colab' in sys.modules:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    base_path = '/content/drive/MyDrive/685-NLP-Project/implicit-hate-detection'"],"metadata":{"id":"JgH7ziijyX9G","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652154131728,"user_tz":240,"elapsed":1206,"user":{"displayName":"Kimberley Faria","userId":"14997609029817023442"}},"outputId":"8be2d599-3560-488b-88f2-d0e27c3163ac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["%load implicit_hate_dataloader/dataloader.py    \n","%load implicit_hate_dataloader/helpers.py"],"metadata":{"id":"lfWIyO6dyqKv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","data_path = '/content/drive/MyDrive/685-NLP-Project/implicit-hate-corpus'\n","dataset_filename = {\n","    # post (str)\n","    # class (str): high-level label in {`explicit_hate`,`implicit_hate`,`not_hate`}\n","    \"stage-1\": os.path.join(data_path, \"implicit_hate_v1_stg1_posts.tsv\"),\n","\n","    # post (str)\n","    # class (str): fine-grained implicit hate label in\n","    # {`white_grievance`, `incitement`, `inferiority`, `irony`, `stereotypical`, `threatening`, `other`}\n","    # extra_implicit_class: (str) A secondary fine-grained implicit hate label in\n","    # {`white_grievance`, `incitement`, `inferiority`, `irony`, `stereotypical`, `threatening`, `other`, **None**}\n","    \"stage-2\": os.path.join(data_path, \"implicit_hate_v1_stg2_posts.tsv\"),\n","\n","    # post (str)\n","    # target: (str) Free-text annotation for the group being targeted (e.g. `Black people`, `Immigrants`, etc.)\n","    # implied_statement: (str) Free-text annotation for the implicit or hidden underlying meaning of the post made\n","    # explicit (e.g. `people in minority groups are all in gangs`)\n","    \"stage-3\": os.path.join(data_path, \"implicit_hate_v1_stg3_posts.tsv\")\n","}"],"metadata":{"id":"0utlzpjF2sVM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from implicit_hate_dataloader.dataloader import Stage1Dataset, Stage2Dataset\n","from torch.utils.data import DataLoader"],"metadata":{"id":"2gkkA-Z-3GGL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","\n","implicit_hate_dataset = Stage1Dataset(dataset_filename[\"stage-1\"], merge_hate_labels =True)\n","\n","dataset_size = len(implicit_hate_dataset)\n","dataset_splits = [int(0.6*dataset_size), int(0.2*dataset_size), dataset_size - int(0.6*dataset_size) - int(0.2*dataset_size)]\n","\n","# # Smaller dataset for testing model\n","# dataset_splits = [int(0.006*dataset_size), int(0.002*dataset_size), int(0.002*dataset_size)]\n","print(\"Dataset size\", dataset_size)\n","print(\"Dataset splits\", dataset_splits)\n","\n","train_set, val_set, test_set = torch.utils.data.random_split(implicit_hate_dataset, dataset_splits)\n","\n","print(train_set[0][0])\n","print(train_set[0][1])\n","print(train_set[0][2])\n","print(train_set[0][3])\n","\n","# for i in range(30):\n","#   print(test_set[i][1])\n","\n","train_dataloader =  DataLoader(train_set, batch_size=4, shuffle=False)\n","validation_dataloader = DataLoader(val_set, batch_size=4, shuffle=False)"],"metadata":{"id":"gSoV4CGOB8yu","colab":{"base_uri":"https://localhost:8080/","height":371,"referenced_widgets":["7a5e4fd113704d8a834454f1204961ce","a6c8474ecf7348c681b1360c0c7958e4","fe098fbd22bb41a998e4639330340d65","c55a2fe024c3426e947edfda29d0f53f","792d4ce519a4495486a2542eab374a1e","ef40a34fe1854bf88542fc6d0e0a2f3a","7534892edb1b4508a498372c54bb5829","499f21441f324aeb987aba045d3f3eeb","23b82d2586364ac5bb84a9decd43e1bc","72a7514489174775a69951a11e2e8915","ee36e7028dc445a095be3b5359669eac","0fd7f98c68694cb1adc98b13f448b3f3","3ca1686d07304ca9ab04fa86f0738a7c","2dbcce59ac4448d0abacf1f4a3e043b0","585283f9873f4d56bcb1a0e36c215a01","95a07eb2009e433a9bca4bd1af30204f","e8675cd5ac144da1bfa53b9a5db0c240","d26a811fc3794b56ac582a05de93aeb9","f0c74b96df6c40fc81083b55f4f14e19","17785e3089eb4c11b8747a42e45c9c06","7944d7e4d2fa46d1a9330a0e4db8364c","5732d44cb6d541baaeb7501d13a51563","764944af5216487b98a0ec6b08fd0fbd","3fe8b72dba5043568433ba55285210b0","74842485987d427da12b04e35ad5310a","fb9339c45d734b6e88f5498b3faeb4aa","f1bdbfc634684c3bb7b84e4153e9794a","77602842054d4cb09d677b533c78b9d0","b77236719bb5453482ab752593e9e6b1","fc3823fb624b4b5cbb790daa658ea3ea","8dbd7fffe42044cbaa3015c105ddc794","7087f4231c664ed39fa60de279b59c6a","5dafd8cd09404578a3411b638b588a9d"]},"executionInfo":{"status":"ok","timestamp":1652154165140,"user_tz":240,"elapsed":20292,"user":{"displayName":"Kimberley Faria","userId":"14997609029817023442"}},"outputId":"bf4147fb-d7de-406c-c2c3-d3ca788da38a"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a5e4fd113704d8a834454f1204961ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fd7f98c68694cb1adc98b13f448b3f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"764944af5216487b98a0ec6b08fd0fbd"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset size 21480\n","Dataset splits [12888, 4296, 4296]\n","crooked cops posted movie  take shelter  showing #endtmes visions as mental illness on my youtube feed\n","not_hate\n","tensor([  101, 15274, 10558,  6866,  3185,  2202,  7713,  4760,  1001,  2203,\n","        21246,  2229, 12018,  2004,  5177,  7355,  2006,  2026,  7858,  5438,\n","          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0])\n","tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"]}]},{"cell_type":"code","source":["text, label, input_ids, attention_masks, labels = next(iter(train_dataloader))\n","print(text, type(label), type(input_ids), type(attention_masks), type(labels))"],"metadata":{"id":"6-WhzqO3B0yi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652154165141,"user_tz":240,"elapsed":16,"user":{"displayName":"Kimberley Faria","userId":"14997609029817023442"}},"outputId":"77976599-2553-41c0-f2f6-ce304a77f75d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["('crooked cops posted movie  take shelter  showing #endtmes visions as mental illness on my youtube feed', 'anti-semitism is recurring problem in dutch schools via', 'i wish they would . thatbwould be one rent-collecting cuck down at election time .', \"filthy jews are not white . and jews don't fight they get others too . you'll find yourself in holocaust mark 2\") <class 'tuple'> <class 'torch.Tensor'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n"]}]},{"cell_type":"code","source":["import torch\n","assert torch.cuda.is_available()\n","\n","# Get the GPU device name.\n","device_name = torch.cuda.get_device_name()\n","n_gpu = torch.cuda.device_count()\n","print(f\"Found device: {device_name}, n_gpu: {n_gpu}\")\n","device = torch.device(\"cuda\")"],"metadata":{"id":"LKVo0dAYF4fc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652154165141,"user_tz":240,"elapsed":14,"user":{"displayName":"Kimberley Faria","userId":"14997609029817023442"}},"outputId":"ae92028a-da0b-4bf9-85bc-8c80b9fcfb73"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found device: Tesla P100-PCIE-16GB, n_gpu: 1\n"]}]},{"cell_type":"code","source":["from torch import nn\n","\n","loss_fn = nn.CrossEntropyLoss().to(device)"],"metadata":{"id":"vzrny80iPOYV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","# function to get validation accuracy\n","def get_validation_performance(model, val_set, config):\n","    # Put the model in evaluation mode\n","    model.eval()\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","\n","    validation_dataloader = DataLoader(val_set, batch_size=config[\"batch_size\"], shuffle=True)\n","\n","    total_correct = 0\n","\n","    for batch in validation_dataloader:\n","      \n","      # Move tensors to the GPU\n","      b_input_ids = batch[2].to(device)\n","      b_input_mask = batch[3].to(device)\n","      b_labels = batch[4].to(device)\n","        \n","      # Tell pytorch not to bother with constructing the compute graph during\n","      # the forward pass, since this is only needed for backprop (training).\n","      with torch.no_grad():        \n","\n","        # Forward pass, calculate logit predictions.\n","        outputs = model(input_ids = b_input_ids, attention_mask=b_input_mask)\n","\n","        _, preds = torch.max(outputs, dim=1)\n","        loss = loss_fn(outputs, b_labels)\n","            \n","        # Accumulate the validation loss.\n","        total_eval_loss += loss.item()\n","        \n","        total_correct += torch.sum(preds == b_labels)\n","        \n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_correct / len(val_set)\n","    return avg_val_accuracy"],"metadata":{"id":"3CVpMJWX3QPS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!wandb login"],"metadata":{"id":"rd5Ps1XM3XWm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652154193431,"user_tz":240,"elapsed":21868,"user":{"displayName":"Kimberley Faria","userId":"14997609029817023442"}},"outputId":"db9b7e0b-d3d2-4ca1-8bcf-de294407acaf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}]},{"cell_type":"code","source":["import wandb\n","\n","sweep_config = {\n","    \"method\" : \"grid\",\n","    \"parameters\" : {\n","        \"batch_size\": {\n","            \"values\" : [8]\n","        },\n","        \"learning_rate\" : {\n","            \"values\": [2e-5, 3e-5, 5e-5]\n","        },\n","        \"epochs\" : {\n","            \"values\" : [1, 2, 3, 4]\n","        },\n","        \"epsilon\": {\n","            \"values\" : [1e-8]\n","        },\n","    }\n","}\n","\n","# # hyperparameters used in original paper\n","# sweep_config = {\n","#     \"name\": \"original-ppr-hparams-sweep\",\n","#     \"method\" : \"grid\",\n","#     \"parameters\" : {\n","#         \"batch_size\": {\n","#             \"values\" : [8, 16, 32]\n","#         },\n","#         \"learning_rate\" : {\n","#             \"values\": [2e-4, 3e-4, 4e-4, 2e-5]\n","#         },\n","#         \"epochs\" : {\n","#             \"values\" : [2, 3, 4]\n","#         },\n","#         \"epsilon\": {\n","#             \"values\" : [1e-8]\n","#         },\n","#     }\n","# }\n","\n","sweep_id = wandb.sweep(sweep_config, entity=\"umass-iesl-is\", project=\"cs685-project\")"],"metadata":{"id":"3Zn8vWnY3Y86","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652154324848,"user_tz":240,"elapsed":742,"user":{"displayName":"Kimberley Faria","userId":"14997609029817023442"}},"outputId":"7dc8f31b-e9d8-4e90-b1e5-2d327e2cfdf1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Create sweep with ID: 9nfybd3p\n","Sweep URL: https://wandb.ai/umass-iesl-is/cs685-project/sweeps/9nfybd3p\n"]}]},{"cell_type":"code","source":["from transformers import AutoModel, AutoTokenizer\n","\n","class SentimentClassifier(nn.Module):\n","\n","  def __init__(self, n_classes):\n","    super(SentimentClassifier, self).__init__()\n","    self.bert = AutoModel.from_pretrained(\"vinai/bertweet-base\")\n","    self.out = nn.Linear(768, 2)\n","  \n","  def forward(self, input_ids, attention_mask):\n","    _, pooled_output = self.bert(\n","      input_ids=input_ids,\n","      attention_mask=attention_mask,\n","      return_dict=False\n","    )\n","    output = pooled_output\n","    return self.out(output)"],"metadata":{"id":"FWlbYcMxKWvk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = SentimentClassifier(2)\n","model = model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dHpFIpO4WdFs","executionInfo":{"status":"ok","timestamp":1652154330580,"user_tz":240,"elapsed":3031,"user":{"displayName":"Kimberley Faria","userId":"14997609029817023442"}},"outputId":"02688914-4b0c-437c-98f9-4b1b65cdbe29"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["from transformers import BertForSequenceClassification, AdamW, BertConfig\n","from transformers import AutoModel, AutoTokenizer\n","from torch import nn, optim\n","\n","def train():\n","    with wandb.init() as run:\n","        config = wandb.config\n","\n","        model = SentimentClassifier(2)\n","        model = model.to(device)\n","\n","        # Tell pytorch to run this model on the GPU.\n","        model.cuda()\n","        optimizer = AdamW(model.parameters(),\n","                        lr = config[\"learning_rate\"], # args.learning_rate - default is 5e-5\n","                        eps = config[\"epsilon\"] # args.adam_epsilon  - default is 1e-8\n","                        )\n","        wandb.watch(model, log=\"all\")\n","\n","        for epoch_i in range(0, config[\"epochs\"]):\n","            # Perform one full pass over the training set.\n","\n","            print(\"\")\n","            print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, config[\"epochs\"]))\n","            print('Training...')\n","\n","            # Reset the total loss for this epoch.\n","            total_train_loss = 0\n","\n","            # Put the model into training mode.\n","            model.train()\n","\n","            # For each batch of training data...\n","            train_dataloader = DataLoader(train_set, batch_size=config[\"batch_size\"], shuffle=False)\n","\n","            for batch_idx, batch in enumerate(train_dataloader):\n","\n","                # Move tensors to the GPU\n","                b_input_ids = batch[2].to(device)\n","                b_input_mask = batch[3].to(device)\n","                b_labels = batch[4].to(device)\n","\n","                # Clear the previously calculated gradient\n","                model.zero_grad()        \n","\n","                # Perform a forward pass (evaluate the model on this training batch).\n","                outputs = model(input_ids = b_input_ids, attention_mask = b_input_mask)\n","\n","                _, preds = torch.max(outputs, dim=1)\n","                loss = loss_fn(outputs, b_labels)\n","\n","                total_train_loss += loss.item()\n","\n","                # Perform a backward pass to calculate the gradients.\n","                loss.backward()\n","\n","                # Update parameters and take a step using the computed gradient.\n","                optimizer.step()\n","                wandb.log({\n","                    \"batch_loss\": loss.item(),\n","                    \"batch\": batch_idx\n","                })\n","                \n","            # ========================================\n","            #               Validation\n","            # ========================================\n","            # After the completion of each training epoch, measure our performance on\n","            # our validation set. Implement this function in the cell above.\n","            print(f\"Total loss: {total_train_loss}\")\n","            val_acc = get_validation_performance(model, val_set, config)\n","            print(f\"Validation accuracy: {val_acc}\")\n","            wandb.log({\n","                \"loss\": total_train_loss, \n","                \"epoch\": config[\"epochs\"], \n","                \"val_acc\": val_acc\n","                })\n","            \n","        print(\"\")\n","        print(\"Training complete!\")\n","\n","        test_acc = get_validation_performance(model, test_set, config)\n","        print(f\"Test accuracy: {test_acc}\")\n","        wandb.log({\"test_acc\": test_acc})\n","\n","        # torch.save(model.state_dict(), \"model.h5\")\n","        # wandb.save('model.h5')"],"metadata":{"id":"cjHJaW_J3etV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["count = 1 # number of runs to execute\n","wandb.agent(sweep_id, function=train, count=count, entity=\"umass-iesl-is\", project=\"cs685-project\")"],"metadata":{"id":"VzVgUrjCI6vp","colab":{"base_uri":"https://localhost:8080/","height":728,"referenced_widgets":["e12a6882b36f41538f9d5be64568f594","556292591616463c87c50e0619139d0b","b871ddd7bfb74843b49f79c8f98922ee","8d9f88b576234af89d574b875c11197b","545105eb33d44b0a823aea304d4f1c99","933ad9befbbf47e889468affed686e98","86e43d01687b483992ca680f3b5c0aa7","6845376d56b64c03b8e51e1daab15c9a"]},"outputId":"b12b05ef-23ac-4eb6-a1a5-842b7ba3c199","executionInfo":{"status":"ok","timestamp":1652154511514,"user_tz":240,"elapsed":179802,"user":{"displayName":"Kimberley Faria","userId":"14997609029817023442"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: me8j5pua with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepsilon: 1e-08\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2e-05\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.12.16"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/drive/.shortcut-targets-by-id/1S8UITZ4wcfheudaDPm55HK4b4g-PPNuD/685-NLP-Project/implicit-hate-detection/wandb/run-20220510_034535-me8j5pua</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/umass-iesl-is/cs685-project/runs/me8j5pua\" target=\"_blank\">comfy-sweep-1</a></strong> to <a href=\"https://wandb.ai/umass-iesl-is/cs685-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/umass-iesl-is/cs685-project/sweeps/9nfybd3p\" target=\"_blank\">https://wandb.ai/umass-iesl-is/cs685-project/sweeps/9nfybd3p</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["\n","======== Epoch 1 / 1 ========\n","Training...\n","Total loss: 989.937154814601\n","Validation accuracy: 0.6906424760818481\n","\n","Training complete!\n","Test accuracy: 0.7057728171348572\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.095 MB of 0.095 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e12a6882b36f41538f9d5be64568f594"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch_loss</td><td>▄▃▆▇▆▆▃▅▃▆▆▃▂▂▂▅▃▄▃▇▆▃▅▄▄▁▄▃▅██▅▅▂▆▅▃▆▁▂</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>val_acc</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>1610</td></tr><tr><td>batch_loss</td><td>0.5772</td></tr><tr><td>epoch</td><td>1</td></tr><tr><td>loss</td><td>989.93715</td></tr><tr><td>test_acc</td><td>0.70577</td></tr><tr><td>val_acc</td><td>0.69064</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Synced <strong style=\"color:#cdcd00\">comfy-sweep-1</strong>: <a href=\"https://wandb.ai/umass-iesl-is/cs685-project/runs/me8j5pua\" target=\"_blank\">https://wandb.ai/umass-iesl-is/cs685-project/runs/me8j5pua</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20220510_034535-me8j5pua/logs</code>"]},"metadata":{}}]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix, classification_report, recall_score, f1_score, accuracy_score, precision_recall_fscore_support\n","\n","final_score = precision_recall_fscore_support(preds, labels, average='binary')\n","class_names=['not_hate', 'hate']\n","wandb.log({f\"conf_mat_{dataset}_{epoch}\" : wandb.plot.confusion_matrix(probs=None,\n","                        y_true=labels, preds=preds,\n","                        class_names=class_names)})\n","cm = confusion_matrix(labels, preds, labels=[0, 1])\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm, \n","                                  display_labels=class_names)\n","disp.plot()\n","\n","wandb.log({f\"conf_mat_matplotlib_{dataset}_{epoch}\": plt})\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":245},"id":"wrPpDWmELVIU","executionInfo":{"status":"error","timestamp":1652154267282,"user_tz":240,"elapsed":348,"user":{"displayName":"Kimberley Faria","userId":"14997609029817023442"}},"outputId":"69c69ace-9b4e-4560-ea2d-9f3f1836dbcc"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-d603ebef1c01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfinal_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'not_hate'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m wandb.log({f\"conf_mat_{dataset}_{epoch}\" : wandb.plot.confusion_matrix(probs=None,\n","\u001b[0;31mNameError\u001b[0m: name 'preds' is not defined"]}]},{"cell_type":"code","source":["def get_predictions(model, train_data_loader):\n","  model = model.eval()\n","  \n","  tweets_content = []\n","  predictions = []\n","  prediction_probs = []\n","  real_values = []\n","\n","  with torch.no_grad():\n","    for d in train_data_loader:\n","\n","      print(d)\n","      print(d[0])\n","\n","      texts = d[0]\n","      input_ids = d[1].to(device)\n","      attention_mask = d[2].to(device)\n","      targets = d[3].to(device)\n","\n","      outputs = model(\n","        input_ids=input_ids,\n","        attention_mask=attention_mask\n","      )\n","      \n","      _, preds = torch.max(outputs, dim=1)\n","      \n","      probs = nn.functional.softmax(outputs, dim=1)\n","\n","      tweets_content.extend(texts)\n","      predictions.extend(preds)\n","      prediction_probs.extend(probs)\n","      real_values.extend(targets)\n","\n","  predictions = torch.stack(predictions).cpu()\n","  prediction_probs = torch.stack(prediction_probs).cpu()\n","  real_values = torch.stack(real_values).cpu()\n","  return tweets_content, predictions, prediction_probs, real_values"],"metadata":{"id":"5aj12jU7NMx5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix, classification_report, recall_score, f1_score, accuracy_score, average_precision_score\n","\n","def show_confusion_matrix(confusion_matrix):\n","  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n","  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n","  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n","  plt.ylabel('True sentiment')\n","  plt.xlabel('Predicted sentiment');"],"metadata":{"id":"ERdPjjkkUYM_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def avg_rec(y_test, y_pred):\n","    rec_n, rec_u, rec_p = recall_score(y_test, y_pred, average=None)\n","    return (1/3) * (rec_n+ rec_u+ rec_p)"],"metadata":{"id":"JmTTwotjUcIY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def f1_np(y_test, y_pred):\n","    f1_n, _,f1_p = f1_score(y_test, y_pred, average=None)\n","    return 0.5*(f1_n+f1_p)"],"metadata":{"id":"_jM0vbyIUeZs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def eval_model(model, data_loader, loss_fn, device, n_examples):\n","  model = model.eval()\n","\n","  losses = []\n","  correct_predictions = 0\n","\n","  with torch.no_grad():\n","    for d in data_loader:\n","      input_ids = d[\"input_ids\"].to(device)\n","      attention_mask = d[\"attention_mask\"].to(device)\n","      targets = d[\"targets\"].to(device)\n","\n","      outputs = model(\n","        input_ids=input_ids,\n","        attention_mask=attention_mask\n","      )\n","      _, preds = torch.max(outputs, dim=1)\n","\n","      loss = loss_fn(outputs, targets)\n","\n","      correct_predictions += torch.sum(preds == targets)\n","      losses.append(loss.item())\n","\n","  return correct_predictions.double() / n_examples, np.mean(losses)"],"metadata":{"id":"jJeS6xbdVkZU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.load_state_dict(torch.load('bertweet_best_model_state.bin'))"],"metadata":{"id":"nXHobQrJWVUU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_acc, _ = eval_model(\n","  model,\n","  validation_dataloader,\n","  loss_fn,\n","  device,\n","  len(df_test)\n",")\n","\n","test_acc.item()"],"metadata":{"id":"a-7Va1gRV435"},"execution_count":null,"outputs":[]}]}