{"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/kimberley-faria/implicit-hate-detection/blob/main/implicit_hate_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1fUCvocV8Wco"},"outputs":[],"source":["# if local\n","# !conda activate cs685"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WF0CuIiKkCD6"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8CMaZaGe-ZaD"},"outputs":[],"source":["BASE_PATH = '/content/drive/MyDrive/685-NLP-Project/implicit-hate-detection'\n","DATA_PATH = '/content/drive/MyDrive/685-NLP-Project/implicit-hate-corpus'"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1456,"status":"ok","timestamp":1652137231987,"user":{"displayName":"Kimberley Faria","userId":"14997609029817023442"},"user_tz":240},"id":"9KgXcm0bC4pZ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"58f02d1c-851c-43ce-e96b-59e42ba48ec6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1652137231988,"user":{"displayName":"Kimberley Faria","userId":"14997609029817023442"},"user_tz":240},"id":"Km7BbPyebrnp","outputId":"88073c1b-c983-48b7-ae5b-279b2f0b1a62"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/usr/bin'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}],"source":["import os\n","import sys\n","os.path.dirname(sys.executable)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1715,"status":"ok","timestamp":1652137233699,"user":{"displayName":"Kimberley Faria","userId":"14997609029817023442"},"user_tz":240},"id":"TWIj6y_D8wpZ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"807b5680-bf03-4b19-a1b6-83cab05e1f69"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import sys\n","\n","if 'google.colab' in sys.modules:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    base_path = BASE_PATH\n","else:\n","    base_path = r'C:\\Users\\faria\\PycharmProjects\\685\\project\\implicit-hate-detection'\n","    DATA_PATH = r'C:\\Users\\faria\\PycharmProjects\\685\\project\\data\\implicit-hate-corpus-nov-2021\\implicit-hate-corpus'"]},{"cell_type":"markdown","metadata":{"id":"gMT_aJYbYvrt"},"source":["switch to the git repo in your drive"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1652137233699,"user":{"displayName":"Kimberley Faria","userId":"14997609029817023442"},"user_tz":240},"id":"6ToiwT8GNVS1","outputId":"d5e520cb-08ab-4339-ea10-d93d5c6d1a82"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1S8UITZ4wcfheudaDPm55HK4b4g-PPNuD/685-NLP-Project/implicit-hate-detection\n"]}],"source":["%cd $base_path\n","# !git checkout 5-bert-baselines-bin-classification-hate-non-hate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kGp_p5xWFLdN"},"outputs":[],"source":["# !git status"]},{"cell_type":"code","source":["!ls -la"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cTHF3tcr_KJY","executionInfo":{"status":"ok","timestamp":1652137233700,"user_tz":240,"elapsed":6,"user":{"displayName":"Kimberley Faria","userId":"14997609029817023442"}},"outputId":"a48a878f-cda9-402c-8d00-2b5c50f9d2f5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["total 1418126\n","-rw------- 1 root root 577996269 Feb 15  2018  Anaconda3-5.1.0-Linux-x86_64.sh\n","-rw------- 1 root root   1347942 May  1 04:06 'Copy of implicit_hate_detection_multi_class.ipynb'\n","drwx------ 5 root root      4096 May  9 22:51  .git\n","-rw------- 1 root root      1813 Apr 30 20:50  .gitignore\n","-rw------- 1 root root 433321325 May  9 21:55  hsol_final_model.bin\n","-rw------- 1 root root     42314 May  9 22:59 'HSOL implicit_hate_detection_multi_class.ipynb'\n","drwx------ 3 root root      4096 Apr 20 16:08  implicit_hate_dataloader\n","-rw------- 1 root root    722226 Apr 30 23:51  implicit_hate_detection_hate_vs_non_hate.ipynb\n","-rw------- 1 root root    578080 May  1 21:28  implicit_hate_detection_implicit_hate_vs_non_hate.ipynb\n","-rw------- 1 root root     44785 Apr 30 20:50  implicit_hate_detection.ipynb\n","-rw------- 1 root root     31698 May  1 16:11  implicit_hate_detection_multi_class.ipynb\n","-rw------- 1 root root     32024 Apr 30 21:55  implicit_hate_detection_multi.ipynb\n","-rw------- 1 root root 438020141 Apr 29 19:05  model.h5\n","-rw------- 1 root root      6293 Apr 30 20:50  README.md\n","-rw------- 1 root root       115 Apr 20 16:08  req_instructions.md\n","-rw------- 1 root root        39 Apr 30 20:50  requirements.txt\n","drwx------ 7 root root      4096 May  9 22:59  wandb\n"]}]},{"cell_type":"markdown","metadata":{"id":"wclElGePY0tZ"},"source":["install requirements from repo "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G8MSToF9QoD5","executionInfo":{"status":"ok","timestamp":1652137238303,"user_tz":240,"elapsed":4606,"user":{"displayName":"Kimberley Faria","userId":"14997609029817023442"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2f32ba4e-82e2-47d3-b762-86ab24a8c9f7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.11.0+cu113)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.3.5)\n","Requirement already satisfied: pydrive in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.3.1)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (4.18.0)\n","Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (0.12.16)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->-r requirements.txt (line 1)) (4.2.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 2)) (2022.1)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 2)) (1.21.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 2)) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->-r requirements.txt (line 2)) (1.15.0)\n","Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.7/dist-packages (from pydrive->-r requirements.txt (line 3)) (1.12.11)\n","Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pydrive->-r requirements.txt (line 3)) (4.1.3)\n","Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.7/dist-packages (from pydrive->-r requirements.txt (line 3)) (6.0)\n","Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->pydrive->-r requirements.txt (line 3)) (1.35.0)\n","Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->pydrive->-r requirements.txt (line 3)) (0.17.4)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->pydrive->-r requirements.txt (line 3)) (3.0.1)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->pydrive->-r requirements.txt (line 3)) (0.0.4)\n","Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->pydrive->-r requirements.txt (line 3)) (1.31.5)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.2->pydrive->-r requirements.txt (line 3)) (1.56.0)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.2->pydrive->-r requirements.txt (line 3)) (3.17.3)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.2->pydrive->-r requirements.txt (line 3)) (57.4.0)\n","Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.2->pydrive->-r requirements.txt (line 3)) (2.23.0)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.2->pydrive->-r requirements.txt (line 3)) (21.3)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.2->pydrive->-r requirements.txt (line 3)) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.2->pydrive->-r requirements.txt (line 3)) (4.8)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.2->pydrive->-r requirements.txt (line 3)) (0.2.8)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.0.0->pydrive->-r requirements.txt (line 3)) (0.4.8)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.2->pydrive->-r requirements.txt (line 3)) (3.0.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.2->pydrive->-r requirements.txt (line 3)) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.2->pydrive->-r requirements.txt (line 3)) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.2->pydrive->-r requirements.txt (line 3)) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.2->pydrive->-r requirements.txt (line 3)) (1.24.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 4)) (3.6.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 4)) (0.0.53)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 4)) (0.12.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 4)) (4.11.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 4)) (4.64.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 4)) (0.5.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 4)) (2019.12.20)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (1.5.11)\n","Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (0.1.2)\n","Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (1.0.9)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (1.2.3)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (7.1.2)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (0.4.0)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (2.3)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (5.4.8)\n","Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (3.1.27)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb->-r requirements.txt (line 5)) (4.0.9)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb->-r requirements.txt (line 5)) (5.0.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers->-r requirements.txt (line 4)) (3.8.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->-r requirements.txt (line 4)) (1.1.0)\n"]}],"source":["# for colab, use venv if in local\n","!pip install -r requirements.txt"]},{"cell_type":"markdown","metadata":{"id":"1hNnkZxzY4jo"},"source":["load the helper and dataloader files"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nWr1Me-jPz2k"},"outputs":[],"source":["%load implicit_hate_dataloader/dataloader.py    \n","%load implicit_hate_dataloader/helpers.py"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8q8KN4enRReS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652137239156,"user_tz":240,"elapsed":857,"user":{"displayName":"Kimberley Faria","userId":"14997609029817023442"}},"outputId":"d32fc99b-b5dd-4854-dc63-03966a58d737"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found device: Tesla P100-PCIE-16GB, n_gpu: 1\n"]}],"source":["import torch\n","assert torch.cuda.is_available()\n","\n","# Get the GPU device name.\n","device_name = torch.cuda.get_device_name()\n","n_gpu = torch.cuda.device_count()\n","print(f\"Found device: {device_name}, n_gpu: {n_gpu}\")\n","device = torch.device(\"cuda\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"67n093r1R-c4"},"outputs":[],"source":["import os\n","\n","data_path = DATA_PATH\n","dataset_filename = {\n","    # post (str)\n","    # class (str): high-level label in {`explicit_hate`,`implicit_hate`,`not_hate`}\n","    \"stage-1\": os.path.join(data_path, \"implicit_hate_v1_stg1_posts.tsv\"),\n","\n","    # post (str)\n","    # class (str): fine-grained implicit hate label in\n","    # {`white_grievance`, `incitement`, `inferiority`, `irony`, `stereotypical`, `threatening`, `other`}\n","    # extra_implicit_class: (str) A secondary fine-grained implicit hate label in\n","    # {`white_grievance`, `incitement`, `inferiority`, `irony`, `stereotypical`, `threatening`, `other`, **None**}\n","    \"stage-2\": os.path.join(data_path, \"implicit_hate_v1_stg2_posts.tsv\"),\n","\n","    # post (str)\n","    # target: (str) Free-text annotation for the group being targeted (e.g. `Black people`, `Immigrants`, etc.)\n","    # implied_statement: (str) Free-text annotation for the implicit or hidden underlying meaning of the post made\n","    # explicit (e.g. `people in minority groups are all in gangs`)\n","    \"stage-3\": os.path.join(data_path, \"implicit_hate_v1_stg3_posts.tsv\")\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"InLTAsNtScfz"},"outputs":[],"source":["from implicit_hate_dataloader.dataloader import Stage1Dataset, Stage2Dataset\n","from torch.utils.data import DataLoader"]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","import numpy as np\n","\n","implicit_hate_dataset = Stage2Dataset(dataset_filename[\"stage-2\"], drop_other=True)\n","\n","labels = implicit_hate_dataset.implicit_classes\n","# splitting into train and test set\n","train_idx, test_idx= train_test_split(np.arange(len(labels)), test_size=0.2, shuffle=True, stratify=labels)\n","print(len(labels), len(train_idx), len(test_idx))\n","train_idx.sort()\n","print(np.arange(len(labels)))\n","print(train_idx)\n","\n","# splitting into train and val set from train indices \n","train_labels = list(map(labels.__getitem__, train_idx))\n","train_idx, val_idx= train_test_split(train_idx, test_size=0.25, shuffle=True, stratify=train_labels)\n","print(len(train_idx), len(val_idx))\n","\n","train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n","valid_sampler = torch.utils.data.SubsetRandomSampler(val_idx)\n","test_sampler = torch.utils.data.SubsetRandomSampler(test_idx)\n","\n","train_dataloader = DataLoader(implicit_hate_dataset, batch_size=8, sampler=train_sampler)\n","\n","# test_dataloader = DataLoader(implicit_hate_dataset, batch_size=8, sampler=test_sampler)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KOHR2i5RvFCv","executionInfo":{"status":"ok","timestamp":1652137252810,"user_tz":240,"elapsed":10339,"user":{"displayName":"Kimberley Faria","userId":"14997609029817023442"}},"outputId":"f4e4fc68-980a-4639-e2c6-fb605f01ae92"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["6266 5012 1254\n","[   0    1    2 ... 6263 6264 6265]\n","[   1    2    3 ... 6262 6263 6265]\n","3759 1253\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zm49lo2jwOEB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652137252811,"user_tz":240,"elapsed":27,"user":{"displayName":"Kimberley Faria","userId":"14997609029817023442"}},"outputId":"d2b57e3d-a1f2-4fba-ba3c-7cf43b2ee812"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'torch.Tensor'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n"]}],"source":["# Confirming type is tensor\n","_, _, _, input_ids, attention_masks, labels, _ = next(iter(train_dataloader))\n","print(type(input_ids), type(attention_masks), type(labels))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y6DWesKexrLl"},"outputs":[],"source":["from sklearn.metrics import precision_recall_fscore_support\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","\n","import numpy as np\n","# function to get validation accuracy\n","def get_validation_performance(model, val_idx, config, epoch, dataset):\n","    # Put the model in evaluation mode\n","    model.eval()\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","\n","    sampler = torch.utils.data.SubsetRandomSampler(val_idx)\n","    validation_dataloader = DataLoader(implicit_hate_dataset, batch_size=8, sampler=sampler)\n","\n","    total_correct = 0\n","\n","    predicted = []\n","    labels = []\n","\n","    for batch in validation_dataloader:\n","\n","      input_id_tensors = batch[3]\n","      input_mask_tensors = batch[4]\n","      label_tensors = batch[5]\n","      \n","      # Move tensors to the GPU\n","      b_input_ids = input_id_tensors.to(device)\n","      b_input_mask = input_mask_tensors.to(device)\n","      b_labels = label_tensors.to(device)\n","        \n","      # Tell pytorch not to bother with constructing the compute graph during\n","      # the forward pass, since this is only needed for backprop (training).\n","      with torch.no_grad():        \n","\n","        # Forward pass, calculate logit predictions.\n","        outputs = model(b_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask,\n","                        labels=b_labels)\n","        loss = outputs.loss\n","        logits = outputs.logits\n","            \n","        # Accumulate the validation loss.\n","        total_eval_loss += loss.item()\n","        \n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the number of correctly labeled examples in batch\n","        pred_flat = np.argmax(logits, axis=1).flatten()\n","        labels_flat = label_ids.flatten()\n","        num_correct = np.sum(pred_flat == labels_flat)\n","        total_correct += num_correct\n","        \n","        predicted.append(pred_flat)\n","        labels.append(labels_flat)      \n","\n","        \n","    predicted = np.concatenate(predicted)\n","    labels = np.concatenate(labels)\n","\n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_correct / len(val_idx)\n","    final_score = precision_recall_fscore_support(predicted, labels, average='macro')\n","    class_names=['white_grievance', 'incitement', 'inferiority', 'irony', 'stereotypical', 'threatening']\n","    wandb.log({f\"conf_mat_{dataset}_{epoch}\" : wandb.plot.confusion_matrix(probs=None,\n","                        y_true=labels, preds=predicted,\n","                        class_names=class_names)})\n","    cm = confusion_matrix(labels, predicted, labels=[0, 1, 2, 3, 4, 5])\n","    disp = ConfusionMatrixDisplay(confusion_matrix=cm, \n","                                  display_labels=class_names)\n","    disp.plot()\n","\n","    wandb.log({f\"conf_mat_matplotlib_{dataset}_{epoch}\": plt})\n","    plt.show()\n","\n","    return avg_val_accuracy, final_score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tHIbTaDVDAKM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652137254681,"user_tz":240,"elapsed":1892,"user":{"displayName":"Kimberley Faria","userId":"14997609029817023442"}},"outputId":"c6c6f396-d4ec-45fb-85e6-1c268ee03d7c"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkfaria\u001b[0m (\u001b[33mumass-iesl-is\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]}],"source":["!wandb login "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JePDf44Y8KCx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652137256617,"user_tz":240,"elapsed":1939,"user":{"displayName":"Kimberley Faria","userId":"14997609029817023442"}},"outputId":"558479b8-69af-4783-904a-062d6151ec10"},"outputs":[{"output_type":"stream","name":"stdout","text":["Create sweep with ID: mcc1ztai\n","Sweep URL: https://wandb.ai/umass-iesl-is/cs685-project/sweeps/mcc1ztai\n"]}],"source":["import wandb\n","\n","# sweep_config = {\n","#     \"name\": \"original-ppr-hparams-sweep\",\n","#     \"method\" : \"grid\",\n","#     \"parameters\" : {\n","#         \"batch_size\": {\n","#             \"values\" : [8]\n","#         },\n","#         \"learning_rate\" : {\n","#             \"values\": [5e-5]\n","#         },\n","#         \"epochs\" : {\n","#             \"values\" : [1]\n","#         },\n","#         \"epsilon\": {\n","#             \"values\" : [1e-8]\n","#         },\n","#     }\n","# }\n","\n","\n","# hyperparameters used in original paper\n","sweep_config = {\n","    \"name\": \"original-ppr-hparams-sweep\",\n","    \"method\" : \"grid\",\n","    \"parameters\" : {\n","        \"batch_size\": {\n","            \"values\" : [8]\n","        },\n","        \"learning_rate\" : {\n","            \"values\": [2e-5, 3e-5, 5e-5]\n","        },\n","        \"epochs\" : {\n","            \"values\" : [1, 2, 3, 4]\n","        },\n","        \"epsilon\": {\n","            \"values\" : [1e-8]\n","        },\n","    }\n","}\n","\n","sweep_id = wandb.sweep(sweep_config, entity=\"umass-iesl-is\", project=\"cs685-project\")\n","# sweep_id = \"gwbynpx8\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xv4NZMApsR88"},"outputs":[],"source":["from transformers import BertForSequenceClassification, AdamW, BertConfig, AutoConfig\n","\n","def train():\n","    with wandb.init() as run:\n","        config = wandb.config\n","        model_config = AutoConfig.from_pretrained(\"./config.json\")\n","        model = BertForSequenceClassification.from_pretrained(\n","        \"./hsol_final_model.bin\", # Use the 12-layer BERT model, with an uncased vocab.\n","        num_labels = 6, # The number of output labels.   \n","        output_attentions = False, # Whether the model returns attentions weights.\n","        output_hidden_states = False, # Whether the model returns all hidden-states.\n","        from_pt=True\n","        )\n","\n","        # Tell pytorch to run this model on the GPU.\n","        model.cuda()\n","\n","\n","        optimizer = AdamW(model.parameters(),\n","                        lr = config[\"learning_rate\"], # args.learning_rate - default is 5e-5\n","                        eps = config[\"epsilon\"] # args.adam_epsilon  - default is 1e-8\n","                        )\n","        wandb.watch(model, log=\"all\")\n","\n","        for epoch_i in range(0, config[\"epochs\"]):\n","            # Perform one full pass over the training set.\n","\n","            print(\"\")\n","            print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, config[\"epochs\"]))\n","            print('Training...')\n","\n","            # Reset the total loss for this epoch.\n","            total_train_loss = 0\n","\n","            # Put the model into training mode.\n","            model.train()\n","\n","            # For each batch of training data...\n","            train_dataloader = DataLoader(implicit_hate_dataset, batch_size=8, sampler=train_sampler)\n","\n","            for batch_idx, batch in enumerate(train_dataloader):\n","\n","                input_id_tensors = batch[3]\n","                input_mask_tensors = batch[4]\n","                label_tensors = batch[5]\n","\n","                # Move tensors to the GPU\n","                b_input_ids = input_id_tensors.to(device)\n","                b_input_mask = input_mask_tensors.to(device)\n","                b_labels = label_tensors.to(device)\n","\n","                # Clear the previously calculated gradient\n","                model.zero_grad()        \n","\n","                # Perform a forward pass (evaluate the model on this training batch).\n","                outputs = model(b_input_ids, \n","                                token_type_ids=None, \n","                                attention_mask=b_input_mask, \n","                                labels=b_labels)\n","                loss = outputs.loss\n","                logits = outputs.logits\n","\n","                total_train_loss += loss.item()\n","\n","                # Perform a backward pass to calculate the gradients.\n","                loss.backward()\n","\n","                # Update parameters and take a step using the computed gradient.\n","                optimizer.step()\n","                wandb.log({\n","                    \"batch_loss\": loss.item(),\n","                    \"batch\": batch_idx\n","                })\n","                \n","            # ========================================\n","            #               Validation\n","            # ========================================\n","            # After the completion of each training epoch, measure our performance on\n","            # our validation set. Implement this function in the cell above.\n","            print(f\"Total loss: {total_train_loss}\")\n","            val_acc, (val_precision, val_recall, val_f1, val_hash) = get_validation_performance(model, val_idx, config, epoch_i, \"val\")\n","            print(val_precision, val_recall, val_f1)\n","            print(f\"Validation accuracy: {val_acc}\")\n","\n","            wandb.log({\n","                \"loss\": total_train_loss, \n","                \"epoch\": config[\"epochs\"], \n","                \"val_acc\": val_acc,\n","                \"val_precision\": val_precision,\n","                \"val_recall\": val_recall,\n","                \"val_f1\": val_f1\n","                })\n","            \n","        print(\"\")\n","        print(\"Training complete!\")\n","\n","        test_acc, (test_precision, test_recall, test_f1, test_hash) = get_validation_performance(model, test_idx, config, 0, \"test\")\n","        print(test_precision, test_recall, test_f1)\n","        print(f\"Test accuracy: {test_acc}\")\n","        wandb.log({\n","            \"test_acc\": test_acc,\n","            \"test_precision\": test_precision,\n","            \"test_recall\": test_recall,\n","            \"test_f1\": test_f1\n","            })\n","\n","        # torch.save(model.state_dict(), \"model.h5\")\n","        # wandb.save('model.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tijcbxfZJ6M6","colab":{"base_uri":"https://localhost:8080/","height":325,"referenced_widgets":["5be312a6d5d647aba42462df5267f846","b58d807edee74684b5c2f34432e2167d","08602935d42241509dff7daf5c63e6df","f9ac80abb8f74bf9b841181755a99051","0616ea1d90094768bb38b3eef6075d77","0ccb0e98f28148c4a82129cabb9fc22e","54f679ebf5714b9dabcd661e257e18da","cc37baaef5e4479988e995023023399f"]},"outputId":"91532261-a5e4-4d90-d93f-a2bf5895fca0","executionInfo":{"status":"ok","timestamp":1652137271507,"user_tz":240,"elapsed":14892,"user":{"displayName":"Kimberley Faria","userId":"14997609029817023442"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: x4qxzakc with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepsilon: 1e-08\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkfaria\u001b[0m (\u001b[33mumass-iesl-is\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.12.16"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/drive/.shortcut-targets-by-id/1S8UITZ4wcfheudaDPm55HK4b4g-PPNuD/685-NLP-Project/implicit-hate-detection/wandb/run-20220509_230058-x4qxzakc</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/umass-iesl-is/cs685-project/runs/x4qxzakc\" target=\"_blank\">scarlet-sweep-1</a></strong> to <a href=\"https://wandb.ai/umass-iesl-is/cs685-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/umass-iesl-is/cs685-project/sweeps/mcc1ztai\" target=\"_blank\">https://wandb.ai/umass-iesl-is/cs685-project/sweeps/mcc1ztai</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.060 MB of 0.060 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5be312a6d5d647aba42462df5267f846"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Synced <strong style=\"color:#cdcd00\">scarlet-sweep-1</strong>: <a href=\"https://wandb.ai/umass-iesl-is/cs685-project/runs/x4qxzakc\" target=\"_blank\">https://wandb.ai/umass-iesl-is/cs685-project/runs/x4qxzakc</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20220509_230058-x4qxzakc/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Run x4qxzakc errored: OSError(\"./hsol_final_model is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\\nIf this is a private repository, make sure to pass a token having permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass `use_auth_token=True`.\")\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run x4qxzakc errored: OSError(\"./hsol_final_model is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\\nIf this is a private repository, make sure to pass a token having permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass `use_auth_token=True`.\")\n"]}],"source":["count = 1 # number of runs to execute\n","wandb.agent(sweep_id, function=train, count=count, entity=\"umass-iesl-is\", project=\"cs685-project\")"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"HSOL implicit_hate_detection_multi_class.ipynb","provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"5be312a6d5d647aba42462df5267f846":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_b58d807edee74684b5c2f34432e2167d","IPY_MODEL_08602935d42241509dff7daf5c63e6df"],"layout":"IPY_MODEL_f9ac80abb8f74bf9b841181755a99051"}},"b58d807edee74684b5c2f34432e2167d":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0616ea1d90094768bb38b3eef6075d77","placeholder":"​","style":"IPY_MODEL_0ccb0e98f28148c4a82129cabb9fc22e","value":"0.086 MB of 0.086 MB uploaded (0.000 MB deduped)\r"}},"08602935d42241509dff7daf5c63e6df":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_54f679ebf5714b9dabcd661e257e18da","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cc37baaef5e4479988e995023023399f","value":1}},"f9ac80abb8f74bf9b841181755a99051":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0616ea1d90094768bb38b3eef6075d77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ccb0e98f28148c4a82129cabb9fc22e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"54f679ebf5714b9dabcd661e257e18da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc37baaef5e4479988e995023023399f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}